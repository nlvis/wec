{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WEC Analysis - NLP + coding\n",
    "\n",
    "*Created 12/03/2019*\n",
    "\n",
    "This notebook is the core of the analysis of results, including further NLP steps such as looking for collocations, counting occurrences and saving and loading files for manual coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import QuadgramCollocationFinder,TrigramCollocationFinder,BigramCollocationFinder,FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.parse import CoreNLPParser\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from IPython.display import HTML, display\n",
    "import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stopws = stopwords.words('english') #Load common stopwords\n",
    "pos_tagger = CoreNLPParser(url='http://localhost:9500', tagtype='pos')\n",
    "excs = set([])\n",
    "Qs = [\"C8P\",\"C6P\",\"C4P\",\"C2P\",\"C0\",\"C2N\",\"C4N\",\"C6N\",\"C8N\"]\n",
    "orderedQ = {'C8P': '9_C8P','C6P': '8_C6P','C4P': '7_C4P','C2P': '6_C2P','C0': '5_C0','C2N': '4_C2N','C4N': '3_C4N','C6N': '2_C6N','C8N': '1_C8N'}\n",
    "floatQ = {'C8P': 0.8,'C6P': 0.6,'C4P':0.4,'C2P':0.2,'C0': 0,'C2N': -0.2,'C4N': -0.4,'C6N':-0.6,'C8N': -0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pairs_na(pairs,fname):\n",
    "    with open(fname,'w') as f:\n",
    "        f.write('Nouns\\t Adjectives\\n')\n",
    "        for pair in pairs:\n",
    "            f.write(','.join(pair[0])+'\\t'+pair[1]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load previsouly processed data\n",
    "data = pd.read_pickle(\"WECdf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('varb', 852),\n",
       " ('vara', 850),\n",
       " ('variable', 506),\n",
       " ('relationship', 348),\n",
       " ('correlation', 328),\n",
       " ('increase', 316),\n",
       " ('high', 256),\n",
       " ('low', 169),\n",
       " ('seem', 151),\n",
       " ('value', 140),\n",
       " ('data', 139),\n",
       " ('appear', 129),\n",
       " ('scatter', 129),\n",
       " ('point', 121),\n",
       " ('positive', 116),\n",
       " ('negative', 98),\n",
       " ('decrease', 97),\n",
       " ('chart', 90),\n",
       " ('random', 90),\n",
       " ('show', 78),\n",
       " ('clear', 69),\n",
       " ('trend', 67),\n",
       " ('strong', 63),\n",
       " ('number', 58),\n",
       " ('line', 54),\n",
       " ('middle', 54),\n",
       " ('dot', 54),\n",
       " ('graph', 52),\n",
       " ('weak', 51),\n",
       " ('two', 51)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xm8l2Wd//HXG3dJARWX0sSyxkxREVdEcck1l6TS0hy0Blt06qeZNs4UM06Tpf4012K0nElTXHMBg1xQUzFANsVdyUotNRyZ4wb4mT+u6+jN1+85fA9nub/L+/l4nAf3ct3397rIPlxc3N/3rYjAzMz6Xr+yO2Bm1qpcgM3MSuICbGZWEhdgM7OSuACbmZXEBdjMrCQuwGZmJXEBNjMriQuwmVlJVi67A81o4MCBsfnmm5fdjV7X1tZG//79y+5Gr2qFMUJrjLMvxzhz5syXI2Lw8tq5APeCDTbYgBkzZpTdjV43depURo0aVXY3elUrjBFaY5x9OUZJf6ilnZcgzMxK4gJsZlYSL0H0gtdffwvpM2V3o9edffan2XPPn5TdjV7VCmOE1hhnd8YYcWMP9ybxDHg5JI2SdHXZ/TCz5uMCXBuHJptZj2uJAixpnqQP5u21JD0jqZ+kkyXNkPSopBPy+TGS/kPS3ZJ+lm+xjqSJkh6WdHZpAzGzptISBRi4FmhflD0IuCUi3gEujojhwHbAtwvtjwY+GxHH5/2hwBfyr8Mkjaj8AEljczGf0da2qLfGYWZNpFUK8ARgdN4enfcBTpb0EDAN+FCh/aSIeKmw//uIeC0X7YnAjpUfEBHjI2J4RAzv33+tnh+BmTWdlngKIiIelzRA0sbAVsADkvYE9gNGRkSbpFcKl7xacQsVtvsBS3u3x2bWClplBgxwPXAmaXYbwADgj7n4jgDW6eTanSUNlNSPtITR/F9zM7Ne1xIz4GwC8ASwa96fApwkaQapoN7XybWTgKuADwOTI+J3nX3Qmmuu1mvPDdaTqVOnNv04W2GM0BrjrMcxtkwBjoingZUK+68Du1dpd3nF/lRgau/2zsxaUSstQZiZ1RUXYDOzkrgAm5mVxAXYzKwkLsBmZiVxATYzK0nLPIbWl5wH3DxaYYzQGuNc0TH25rPDngGbmZWkZQpwdyMpJf1K0sx8n93KHIuZNYeWKcB0P5LyyxGxPXA8cFIf9dnMmlgrFeAVjqSUtDZwiaTZwGVUCe5xHrCZdVXLFOCIeBzoLJJyW+C1wiXFSMqTgZeBYcDnO7i/84DNrEtapgBnKxpJOQB4Ii9ZHNI3XTWzZtdqBXgC6dVC1+T9KcDGOZLyS3QcSXkp8C1JDwBtwOLe7qiZNb+Weg64G5GUDwNbFg6d19nnOA+4ebTCGKE1xlmPY2y1GbCZWd1wATYzK4kLsJlZSVyAzcxK4gJsZlYSF2Azs5K4AJuZlaTpnwOWtDWwV0R0GAQq6cWI2LDK8QXAFhHxZlc+03nAzaPMMdbbM6vW85q+AEfEPGDe8pr1RV/MzIoaYgmiO1m+kkZJujqf21rSfZJmSZosafX8Ee/ktg9JujWnnxU/X5LOy581TdI2ffobYGZNqSEKMN3P8m33GLB7RGwH/AHYNx//IHBpRAwDZgInVlz3GeCN/FlfAc7pmWGZWStrlAK8wlm+FXYGbs+5vofyXvrZaxExPW/fDOxYcd1I4Ih83RXAupU3dh6wmXVVQ6wBR8TjkjrL8m2T9Erhkler3gj+CxgdEbMkFWexKmz34/1rwgJOj4irOunjeGA8wCabDImFC2sampm1sEaZAcOKZ/kW9QeekrQmsE/h+Fr5HpDyfmdUXHcPcLSklQEkDe7GOMzMgAaZAWcTgCeAXfP+FOCknOU7g46zfIvOJq3xPgfcVjg+HThW0oXAC6TM4KIbgZ2A2ZLeAW4AxnX0IY6jbB6tMEYrT8MU4G5k+U4Fpubts4CzqlxTuebbfnxIYffU/GNm1iMaaQnCzKypuACbmZXEBdjMrCQuwGZmJXEBNjMriQuwmVlJGuYxtEbiOMr64ud4rV6VPgOWNE7SV5fT5tOF7e9I+ngPfv6CQipa8XiPfo6ZWaW6nwHnIng0cCtARPy4Lz63rz7HzFpXr86AJQ2RdIOkK3NS2DGSZkqaI6ny675I+qKk6ZIekXRmPnw5sJ+k2ZK2lHS5pP1z+6Py8bmSflS4z9xCfu/97dkNki6Q9ISk+ZKOyc0D+K6kB3NO8Mdz2+LnPCLpsnx+kqQBvfabZmYtoy+WIA4Gfpp/PYaUqbAz8P0qf/W/MSJ2ICWeHZYL3T8BkyNi24iY394wB7R/lxQVuQ2wmaRD8+mtgWtzfu/vgKMkrQMcEhEfBz4JXNd+K+CpiNgJ+E/g61XGsCVwSc4Rns3784IdR2lmXdYXBfjpiLiXlLE7lBSc8wCwJrBRRdujJU0HZgGbAIM6ue+OwNSIWJTT0a4F9sjnFkVEezjPfGCDiPgbcJ+km4Fdc5ZEu4nFtlU+69WIaE9IuwHYobJBRIyPiOERMbx//7U66baZWdIXa8Dt2bwizXCXeUuFpPZfPwKcAuwSEa9Imrmc+67Msn+AFDN9X69oK4CI+KKkHYCzJF0fERdUaS/er/j7VC0v2Mysy/ryKYjfA/tIWg+qZuquDbyci+/mpL/2A7Tx/pkypPjJvXJQu4AjgLs7+nBJq0oakN988X1g7y70/QOSRubt0aT4SjOzbumzpyAi4nlJpwN3SVoKPA8cWGgyB3hB0hzgUd5bFpgFLMmvHjqucL8XJJ0B3A8sJQW139RJF/qTXke0MrAE+McudP8F4BhJFwB/5v15wctwHrCZ1aJXC3BELCD9g1v7/tXA1RVtxhV2R1NdcbY6pnDtlcCVVT53w8L25YVT21dpO6SwPZX3soPHFJopIv6hg76Zma2Q0r+I0SCqrQubmXWLC7CZWUlcgGtQXNIwM+spLsBmZiVxATYzK4kLsJlZSeo+Da0ROQ+4PH4u2RpJ082AiylmHZxfXdI+hf2zJHWWOWFm1iuargDXYHfg3QIcEadExMIS+2NmLaqUAizptJwJ/IikXfKsdXbOCt4ztxkj6T8k3S3pZ5JGSfqppImSbincZ6akhyTtVeVzTs4RkY9KOiHPdM8Fjs2fN1DSVElb5Pan5H7NlfStfGyIpMmS/itf8xtJq/Xd75aZNas+XwPOaWQHANtHxBJJ3wH+EhHbSvoQcKekobn50bndS5JGkTIYdoyIxyUNA4ZGxPY52OdOUg5w0cURcU7OHX4sIi6UdBawRUSclvvT3q/hwCHAcNI33+6UdDewEBiVr3lW0jW5/7+uGNdYYCzAoEHr9NDvlpk1szJmwCOAWyJiSd7flZTlS0T8GXgK+Lt8blJEvFS49oGIeDxvjwR2lzQb+C0wKAftFJ2cQ3ymAR9aTr92A26KiMUR8TZwU/4MgMcj4tm8XTUz2HnAZtZV9fAURGe5vq9WtH21ot1FEfHDYoPCjHZPYD9gZES0SXqlG/2omi9sZtYdZcyApwGHFGar95LjHSVtDHwMeLyDa4vuBT4nac18bWW+8ADgj7n4jgDa1wU6yhe+C/hMzg1eDfhM/gwzs17R5zPgiJgm6bfArByk/g3gy5LmA28AYyPirfaZbCf3mSnpv4HpkpaQAt+LkZFTgJMkzSC9Bqn9FUW3A6dJ+j1pzbd4v+tIucSLgcsiYpakIV0do/OAzawWpSxBRMQZwBmFQ+97k0VFju8yWb2FY+cB51UcG1PY3b3KfReybC7wqMK5c4BzKtovYNlM43GV9zQzWxGt+BywmVldcAE2MyuJC7CZWUlcgM3MSuICbGZWEhdgM7OS1MM34ZqO84D7jp9DtkZW9zNgSRtI+kHZ/TAz62l1PwOOiL8Ap5fdDzOzntYIM+AhkqZJGifpB5LulPSUpK/n8/0knVfIFx6S255WuG4NSb/M2cB3SfpwvvaLkqbn687Mx7bPub/zJN0vaZWOrjcz6466L8AVtie9zWJH4Hv52GhgcERsQ8oHXpCPfx7YM391+GvA7yJiOOmrxu3X3hgROwBbAYdJGgD8PXB+RGwN7BsRizu5/l2SxuYCPaOtbVFPj9vMmlDdL0FUmBIR7wB/k/RmTi0bAdwIEBFLC22viYg38vZI4BOSvgasBLRn+x6dg9RXATYBBgFXA5dKWhf42XKuf1dEjAfGA2yyyZBY6JccmdlyNFoB7koub2V28LER8cC7B6SPAKcAu0TEK5JmAkTE/ZJ2BI4Hpknaudr1Zmbd1WhLENVMAw6Hd9eDV6nS5h5gTPtOzg5eG3g5F9/NgS3zufUj4n9zMtpfgI90cL2ZWbc02gy4mmuAkZLmkmaqh1ZpczFwkaR5ef984FLgBUlzgEeBifncUZK+AiwFHgTmAo9Vuf4/O+qQ84DNrBZ1X4Ar83gLx4cUdr9RcXpcRds3gS9Xuf3oKsfOzT9FHV1vZrbCmmEJwsysIbkAm5mVxAXYzKwkLsBmZiVxATYzK4kLsJlZSer+MbRG5Dzg2vgZYmt1LTMDbk9Vq3J8vKQOv9Lc0XVmZt3V8jPgiBhbdh/MrDW1zAw4WyXn+s6RdJuk1SQtkLS6pJUl/ULSXEkTJE2UtEVH15U6CjNrCq1WgLcGxuXs4EXAAYVznwdWjYihwKnA3jVeBzgP2My6rtUK8GMR8XTeng9sUDi3E+/lCi8AHq7xOvI14yNieEQM799/rR7vuJk1n1YrwJ3lCQuIwv6SGq8zM1shrVaAOzMdOBhA0kak1xSZmfWaln8KouBqYL+cK/wwKQN4hTgP2Mxq0TIFuDJXOL+sE+CnhWZHt29IehB4s5PrzMy6xUsQmaRB7a8ayq8o+jDwp3J7ZWbNrGVmwDUYBNwoaSXSP7J9IyKWLOcaM7MV5gKcRcQzwDZl98PMWoeXIMzMSuICbGZWEhdgM7OSeA24FzRDHrCf7zXrfS09A3bWr5mVqaULsJlZmVyAAUnrSvq1pNmS7pc0VNLHJN2dzw+UtETS0Lz/S0l7lNtrM2t0LsDJvwKTI2Jb4GvALyLiSeBDklYFPgU8COyb2++Y99/lPGAz6yoX4GQ34FqAiJgDrC5pbWAGsB2wP3Am8ClJmwAvRMSbxRs4D9jMusoFOFmZZX8v2vN+7wZGANsCE4F1gL3ycTOzbnEBTu4CvgAgaTvgjYh4jVRoPws8EhHvAPcCX8UF2Mx6gJ8DTr4H/FLSV4DXgGMBImJ+TkY7P7ebDHwDeKCzm7VKHrCZdU9LF+CKrN9Pd9Bm/cL2ZMBvRDazHuElCDOzkrgAm5mVxAXYzKwkLsBmZiVxATYzK4kLsJlZSVr6MbTe0mh5wH5m2awcngGbmZWkaWfAkjYFJgD9gaXAfsB3ScE7S4DjI2KOpGHAhcCawB0RcbKkUcA/AGsBHwUuBTYF9gb+BuwfEW/07YjMrNk08wx4NDAlIrYmFd0RpIyH4cBXgHNyu58Ah+Uoyk0l7ZaP7wkcBewK/AC4J9/rz8ABfTcMM2tWTTsDBm4BbpQk0gx3JHCopPbiGTlycntgSmrGB0gz3T8D0yNiEYCkvwJ35OueAAZXfpikscBYgEGD1umtMZlZE2naGXAOVB8GPEtKMRsInB4R2+af7Uixk88Vjm0eEVfmW1QuMbxV2FbFOecBm1mXNW0BlrQesDgifg7cR5oRHy1p5Xx+cET8D/CWpF3zsf6S1iyt02bWUpq2AJP+wewRSbOBQaQoyYeB2ZLmkmIlAY4BzpY0B7iHFLpuZtbrmnYNOCImkJ6CKDo1/xTbzSH9Q1vRn4CphTZDCtvjlvfZzgM2s1o08wzYzKyuuQCbmZXEBdjMrCQuwGZmJXEBNjMriQuwmVlJmvYxtDI1QhylH5MzK1/Lz4AljZF0Ztn9MLPW0/IF2MysLB0uQUj6BRAdnY+I43qlRz1A0jxgv4h4XtJawBxgc+D/AV8gZQRfFBEXVly3ANgiIt7MmcBfjYgjJW1GygQeBMwHxkTEkj4bkJk1pc5mwFeTvsr7Fin9axJwE/AmsKDXe9Y91wLti7AHAbdExDvAxTkPeDvg212437nACRExDHgROLKygaSxkmZImtHWtqh7vTezltDhDDgiJgNI+l5EjCicuknSvcC/9XbnumECcAlwESmY/dx8/GRJh5P+4PlQF+43ArgqZwavAbxc2SAixgPjATbZZEgsXLjCfTezFlHLUxBrS/pYztdF0kdJfxWvWxHxuKQBkjYGtgIekLQn6bVEIyOiTdIr1S4tbPcvbC8BtouIDpdkzMy6qpYCfAJws6TFeX9V4Ou916Uecz1wJjApIkLSAOCPufiOoHrs5EvAFsBs4MDC8emkZYerJK0KrJGzhM3MVlgtBXhhRHxC0kBAEdEof7meQHp9UHvU5BTgJEkzgBmkkPZKPwCuLbyCaN18/ETgMkmn5f3jgJkdfbDjKM2sFrUU4MuBYRHxai/3pUdFxNPASoX914Hdq7S7vLB9E+kfGivb/AHYp1c6amYtq5bngK+SdKqk9SWt2v7T6z0zM2tytcyAPwusB3y1cCyAj/RKj8zMWsRyC3BE7NQXHTEzazXLLcCSViHNfvfIh6YCP4uIxR1eZGZmy1XLGvDFwIdJj3T9iLT0cHFvdsrMrBXUsgY8PCK2K+xPlzSrtzpkZtYqainASyUNjoiXACR9kJQNYR2o9zxgP6NsVh86XILIKWIApwH3SbpZ0kTgHuCkvuhcb5J0dU48q3ZudUl+7tfMelVnM+A5khYC7cE7TwKLgYcj4u2+6FyJdgf2Am4vuyNm1rw6S0P7SF5uGEH6Ou8JpICaaZLuK36DrFFIOouU8fAHUqYFkk6mkBEMXElKT1tP0v7AKGB74D+ANUnZwl9yMI+ZdVena8AR8TwpG+FW0mNoewKfAz5B+opyw8gBPDsBQ4GBpJwISBnB50haHXgsIi7MhXqLiDgtX/s7YOcc6jMF2BqYW3H/scBYgEGDquX8mJktq7M3YmwPfCr/DCItRdwB/HtENGLi+I7AzRGxFHhF0rR8vJaM4AOA70haE9iUKklqzgM2s67qbAY8FfgL8BPgqoh4Xwh5gxHL5v0uzsc6zQjOM+NLgF0iYoGk6/ukt2bW9Dr7IsYg4O/zr9dJmi7pXEkHS1q7b7rXo2YAB0nql6M1dwI6yghuAzbK22sAS4HnJK3He/GWZmbd0tk/wi0hZebeB/ybpE2BrwAXAB8k/yNWo4iIe/LLOh8GngHuBN4GNq6SEXw7cJqk3wOHkMLdHwaepUpcZSXnAZtZLTpbA96S956A2Al4A7gf+A5pPbjhRMQ3qxyeVKXdQtKTD+2qXWdm1i2drQFfQiq0E4BvRsRrfdMlM7PW0NkSxB4dnTMzs+6rJQ3NzMx6gQuwmVlJXIDNzEriAmxmVpJa8oCti+oxD9jPJZvVH8+AzcxK4gJsZlaShi7Aks6RNEPSfEmjJY2TdIGkeyQ9LukLud0YST+XdIekx3IGMErOy/eYJmmbfHxvSQ9KmifpitxuiKQbJF2Zv7psZtYtjb4G/M8R8UYOjr8VuJkUF7kHMJj0AtGbc9ttgF2AVYCZkq4jfd34jYgYLmkr4DxgH6Ba/u9rwMHAXhHxvq9iOw/YzLqqYQuwpFWAH0ragzSTH5BP3ZHfVvHXHL7z8Xz8nvwqpbcl3Q4MA0YCh0o6ILdpj6uslv/7GvB0teILzgM2s65r2AIMHA1sSAoKWg2Yl48Xx9SP94pqteMCTo+Iq9pPLCf/99UeHYGZtbRGXgMeADyTZ7WHFI7vlzN/NwC24r1XD+2V33bcH9gbeIj0huejJa0MIGkwzv81sz7SyDPgCcBESXsDk4Hn8vHnSYV1PeCUiHhdEsCjwG2koPWfRsRzkv5ImkHPlvQOcENEjMuz3przfys5D9jMatGwBTgiXiCt475L0jjggYgYU+WSJyPisxX3CODU/FM83lH+784r2l8zs0qNvATREXXxuJlZKZqxAJuZNYSGXYKoJiLGdXD88r7tiZnZ8nkGbGZWEhdgM7OSuACbmZWkqdaA64XzgM2sFi07A5a0f/s34PL+p8vsj5m1npYtwMC/kP8GIOnjpGwJM7M+09BLEJI2JX0luT8pv2Ff4J+APUljOwh4C/gVMBB4AzgM+DywA/CgpKtIWRKfkDQb+GJudykwCJgPjAE2Bv5/Pvd3ETG8TwZpZk2r0WfAo4EpEbE1sBs5BzgitgGGRsQC4EVg/4jYjpQZfGREXEjKjNgpIs4kFe3JEbFtRMwHzgVOiIhh+foj8+cdTMqReF/xlTQ2B7vPaGtb1JtjNrMm0dAzYOAW4EaltJ0LgRHAjQARsTS3+STw4xzavi5wWQ33HQFclUN81gBezsedB2xmPaahC3BEPClpGGn99l7gvirNLgLOiYibJZ1IKsLLswTYLof1ACBpCM4DNrMe1NBLEDmvd3FE/JxUfCcDh+dz/fJbMwYAj+UnHg4sXN5Giqas3AaYTl52kLSqpAGYmfWwhp4Bk4LVvy/pbWAB6Z1wIyXNJaWfHQr8GJhEWvOdwntjvhiYIukXuc0SSQ8BxwEnApdJOi23PQ54pdZOOQ/YzGrR0AU4IiaQnoIo+kbF/jOkpyAqr72ItDzRbu+KJvtU+UjnAZtZj2noJQgzs0bmAmxmVhIXYDOzkrgAm5mVxAXYzKwkLsBmZiVp6MfQ6lU95QH7eWSz+uUZcCZpZUmX1NDOucFm1iNcgLOIWBIRX+usjaQPAKf0UZfMrMk1dQGWNETSnZKukzRP0hWSVpF0lKTZkuZK+lGh/Yv51zGSzpf0G0mPS/pBbjIeGJ6vrfZNOTOzmjV1Ac52Ab6VM4P7AV8AvguMBLYBNpN0aJXrRpHC27cGviRpECk3eF7ODb692Nh5wGbWVa1QgB+LiD/l7RuAk4GpEbEox01eSwpyrzQ1It6MiLdJeRLrd/YhETE+IoZHxPD+/dfqyf6bWZNqhQJcfNKjH7ASy45bHVz3esV+R+3MzFZIKxTgv5P0kbx9OPBDYC9JA/KbNI4A7q7xXm3Ahr3QRzNrQa3wHPAjwI8kbQHMAq7Jx+8nvchzUkTcVMuNIuIlSb+TNA/4TkTcVq2d84DNrBatUIDfjIjPVRy7Mv8sIyI2zL9eXnF8VGHbr683sx7RCksQXrs1s7rUCgXYzKwuNfUSREQswK8RMrM65RmwmVlJXIDNzEriAmxmVpKmXgOuJGkD4B8j4nRJGwIbR8SMfG48cHz+enK31EsesJ9FNqtvLVWAI+IvwOl59xDS3wBm5HNjy+qXmbWmhlqC6Eq8pKSBkm6X9Ehuu1W+fpqkzUmF+HRJ9+f2CyStnX9dLR/7mKQH8vZpkmZKekjSXmX9HphZ82jEGfAuwMci4k+SfkWKl/xOPv6/wIQcL7kS8HxE7CNpdWAJsDFARDwl6RfAixHx08K93wbuBPYBJgKjgWskDQOGRsT2kgbnNlv3xWDNrHk11Aw4qzVe8h7gE5LOBzaKiCU13v8aUuEF+Ey+30hgd0mzgd8CgyQt84eX84DNrKsasQDXFC8ZES8DOwFTgdsk7VDj/W8HRkjaDHg7F3sBF+Ug9m0jYuPKgu48YDPrqkYswDXFS+Y3WPSLiBuAq4ARFfdpAzaqvHkurHcDZ/Bectq9wOckrQmQlyHMzLqlEdeAa4qXlLQ7cImkt4GFwJHAmoX73ADcImm/iKj8uvIE4DfkF3BGxExJ/w1Ml7QE+D3wD70zPDNrFY1YgGuKl4yIe4BPVrl+53z+aWDLQvshhe07gFUq7ncecF4tHXQesJnVohGXIBwvaWZNoRELsJlZU2ioJQjHS5pZM/EM2MysJC7AZmYlcQE2MyuJC7CZWUka6h/helL+IseSHMyzMnBBRHytJ+5dRh6wnzs2azytPAM+Btgc0tePe6r4mpnVqq4LcM7vnSzpv3Le728krSZpX0nTc/7vSbntWpJuljRL0vicTLZ6PvernOU7T9JuknYlfZX4IknX5TYvStpQ0iOFz99X0tVKzsv3nCZpmzJ+P8ysuTTCEsQoYIuIeFbSNaSIyG+SIiffAn4n6XrgKGBeRBwiaReWzWr4ckS8kQvvtyPicEkTgasj4jftjSLiRUl/kfTJiHiEFPYzIX/mGxExXNJWpK8k71PspKSxwFiAQYPW6Y3fBzNrMnU9A84ej4hn8/Z8YAPgE6TwnZnAhsCmpOjJGwEi4gHgFQBJa5NCeWYDlwHLq47XAKMl9QP2Bm4j5QEfke9xBbBu5UWOozSzrmqEGfDrFftrAA9GxH7Fg5K+DRRfqNme13sy8DIwjBTOc8FyPu96UtG9K3/Omznm8vSIuGrFhmBm9n6NMAOu9CopE/ijAJLWkbQSMB04OB8bCqyf2w8AnoiId0gv4mzXUR7wS8DfgONJyw+Q3q5xdPtbMJwHbGY9oRFmwNUcB1yblwneJK0Hnw9cJekhYBrwfG57Kem9bseSCurifPyXwC8lfToiRrOsCcBZ+XMgLW3sBMyW9A4pS3hcR51zHKWZ1aKuC3Bl+E5EjCucHlbR/C3gwPYdSYcBiyPiYQq5v+RM34iYBnyscO8NC9uXkdaL2/cDODX/mJn1iEZcgqhK0kaS1srbI4FXImJpyd0yM+tQXc+Au2gIcGleIlgK+IsVZlbXmqYA50fPqr2CyMysLjXNEoSZWaNxATYzK4kLsJlZSZpmDbie9HUcpZ85NmtMDTEDzolko8ruh5lZT2qIAmxm1ozqtgBLOkvSI5ImAevlY8fkXN85kr6Qjw3OOcCzJU3Nx6ZKGpuPHSRpM0l3SHpI0hWFTIdzcsbvfEmj87G/l/R4zg6+OB+rer2ZWXfUZSGRNIKUvTAUGAg8QQrOOSYfXwWYJelGUibDrRExPofytBsWEdvm+/0aOCEiHpV0NnAkKVbyn3NO8AeBW0lJaCcDB0TEM5I+kO91bgfXF/vsPGAz65K6LMDAjsDN+avEr0iaRoqlHArMyG3WJBXlEcD3ASq+enx5YXsEKagHUpzly5JWAX4oaQ/S3wQG5LbjSeE955CygateX9nhiBifr2WTTYbEwoUrOnQzaxX1WoDFstm+i/OxGyPi+GUapqJYzauF7SXAdjlUp/0+ABP4AAAI5UlEQVS6Y0lh7jsBqwHzACLiwjxj/hfgs8DoatebmXVXva4BzwAOktRP0kBSkVwT2EdS+3pweybvNFKRpP0dcFVMJy0bIGlVSQNIM95nIuJtCjnBktaPiD8B3wJ27eR6M7NuqcsZcETcI2ke8DDwDHAnKd/3dOAuSUvz/oHA94DLJX2dNOvdo8otTwQuk3Ra3j+OlPk7UdLewGTguXzuAklbkmbc/9rJ9TM76r/zgM2sFnVZgAEi4psdnLq6ot1fKeQA52OjKvb/QMVLNLPKTGEi4ogqxzq63sxshdXrEoSZWdNzATYzK4kLsJlZSVyAzcxK4gJsZlYSF2Azs5LU7WNojayv8oD9rLFZY2vJGbDzhc2sHrRkATYzqwcNU4AlDZF0g6Qrc4bvyfnXRyWdkNuMkXS+pN/kTN8fFK5/X75wPn5Uzg2eK+lHheNzJV0kaZakX0r6cs4Dni9pqz4dvJk1pYYpwNnBwE8jYjhwcf51O+DbhTajgMOArYEvSRpUkS/8pXwNOQf4u8BIYBtgM0mH5vtsDfwiIrYDNgO2iYhhwHnk3N+iHAA/Q9KMtrZFPTxsM2tGjVaAn46Ie/P2yZIeIqWhfajQZmpEvJlTzp4B1qeQLxwRr+RryMenRsSiHDV5Le+F+bwWEe3Zw08Bd+TtJ4D2JLZ3RcT4iBgeEcP791+rZ0ZrZk2t0Z6CeBVA0p7AfsDIiGiT9EqhzesV14jq+cKQxt+vom27Nyru81YH7czMVkijzYDbDQD+mIvvCGB57wCqli8McB+wl6QBSsnuRwB391qvzcwKGm0G3G4KcJKkGaTiel9njTvIFyYiXpB0BnA/sBSYFBE3dbdzzgM2s1o0TAGOiAXAznn7dWD3Km0ur9gfVdiumi8cEVcCV1Y5vmFhe0xheyowtSt9NzOrplGXIMzMGp4LsJlZSVyAzcxK4gJsZlYSF2Azs5K4AJuZlaRhHkNrJM4DNrNatNQMOKelndmN61eXtE9P9snMWldLFeAesDvgAmxmPaLpC7Ck0yTNkfQIsBGwqaQpVfKCz8lxkvMljc7HxuXrp0n6CXAucGzODx5YzojMrFk09RqwpB2AA4DtI2KJpONIOb87kLIfnpJ0dkQsBP45It7IGcG3Atfn23weGJHPjQG2iIjTqnzWWHJO8KBBy8sGMjNr/hnwCOCWiFiS998B7oyIN4p5wZJWAX4oaRZwG8umq10TEZXRlO/jPGAz66qmngF3oFpe8NHAhqSYytWAeYXzr/ZRv8ysxTT7DHgacIik9j9oVuug3QDgmTwrPqST+7WR1pHNzLqtqWfAETFN0m+BWTlw/aoOmk4AJkraG5gMPNdBu9uB0yT9HjgkIl6s1sh5wGZWi6YuwAARcQZwRgfnRhV2h1U5P65ifyGwfQ92z8xaWLMvQZiZ1S0XYDOzkrgAm5mVxAXYzKwkLsBmZiVxATYzK0nTP4ZWht7MA/bzxWbNo2VmwJJGSbq67H6YmbVrmQJsZlZvmrYAS9o05/jOkzQbWB8YKOnXkh6RdHmh7VE543eupB/lY1dK2jNvnyPphrz9UUl3lTAkM2syTVuAgdHAlIjYGtgN+Cvpa8THAVsBW0jaNuf/fhcYCWwDbCbpUODufB3AjsBGklbK7e6u/DBJY3Og+4y2tkW9PDQzawbNXIBvAQ6XdAbQPx97ICL+FhEBPAZsQCquUyNiUT5+LbAHcA+wq6RNSJGUc0hxlVULsPOAzayrmrYAR8STpICdZ4F7gU2pngW8Msv+Pihf/xiwGbA/KSHtdtL74IYDD/Rm382sNTRtAZa0HrA4In4O3Af8TwdN7wP2kjQgR1YewXsz3LnAGGASqQDvB7waEW/2Zt/NrDU083PAewPfl/Q2sAB4u1qjiHghL1PcT3pP3KSIuCmfvhs4MSKeAZDUj7Q00SnnAZtZLZq2AEfEBFLQetGkwvkxhe0rgSur3OMi4KLC/i493lEza1lNuwRhZlbvXIDNzEqi9OSV9SRJi4DHy+5HH1gPeLnsTvSyVhgjtMY4+3KMm0bE4OU1ato14JI9HhHDy+5Eb5M0o9nH2QpjhNYYZz2O0UsQZmYlcQE2MyuJC3DvGF92B/pIK4yzFcYIrTHOuhuj/xHOzKwkngGbmZXEBdjMrCQuwD1M0imSns5h8BuU3Z/ukLSxpEmS5ku6R9IH888MSU9J+sdC24Yet6TBkl7Or65q1jEOlXRXfvnAV5pxnJLOzy9hmC5pWN2PMSL800M/pMjL6cBKwMHAZWX3qZvjGQzsnrdPBH4M/Bw4NI9xGvDhZhg3cDkpfGlUM44RWAV4FNiucKypxkmKir0jb+8B3FzvY/QMuGftSUpTWwrcRvo/c8OKiJcioj39bQEwkBRIf1se40RgXxp83JL2B14kZUdDE46R1N+ZETGrcKzZxvka0D/Hyg4gvUihrsfob8L1rPXJX3WMiCWSVpWkyH8kN7jPkd4ycmBEtEd7/hXYCHiLBh23pP7AqcBBwMX58BrNNMZsK2CxpHuB1YGTaLJxRsQTkqaQZrrvAIcD0+t5jJ4B9y6V3YGeIOlAYGPgOtJ/2O+eovoYG2nc/w78OCKKb0tptjECrAlsCHwKOIb0TGxTjTO/hOEA4CfA/5Jmu3U9Rs+Ae9YLwOYAklYGljbCzKEzkjYHzgT2jYiQ9LqkVfOsYjBpVtFG4477MOAz6W+trEd6BdVrTTZGSGO4PdLbXB6VtBbQ1mTj/CJwU0T8StJNwHygrv979Qy4Z90BHJjfnnwgNbw9o57l/5NeBYyJiBfz4anAQXmMB5Ne1dSw446IzSJiSEQMIc3wjwTupInGmE0FDpG0sqSPkv4KfhfNNc7XSbN8gHWBN6nz/149A+5BEfG8pCtIUZSLSP+DN7ITSDOFn+cZ4iLgs6R/XT4H+M+IeAqgycb9fZpsjBHxpKTrgFnAEtL/tk/SXOO8Athf0hwgSGOcSx2P0V9FNjMriZcgzMxK4gJsZlYSF2Azs5K4AJuZlcQF2MysJC7AZmYlcQE2MyuJC7CZWUn+D2+YhPZAoIe/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_counts = FreqDist()\n",
    "for sent in data.itertuples(index=True):\n",
    "    ws = [func for word,func in sent.lemmatized if (word not in en_stopws)]\n",
    "    pos_counts.update(ws)#word for word in tokens if (word not in stopws))\n",
    "#pos_counts.plot(5)\n",
    "\n",
    "lemma_counts = FreqDist()\n",
    "for sent in data.itertuples(index=True):\n",
    "    ws = [word for word,func in sent.lemmatized if (word not in en_stopws)]\n",
    "    lemma_counts.update(ws)#word for word in tokens if (word not in stopws))\n",
    "#for f,s in lemma_counts.most_common(30):\n",
    "#    df.\n",
    "display(lemma_counts.most_common(30))\n",
    "hfont = {'fontname':'Merriweather Sans'}\n",
    "lcd = pd.DataFrame(lemma_counts.most_common(20),columns=['Word','Count'])\n",
    "lcd = lcd.sort_values(by=['Count'],axis=0,ascending=True)\n",
    "ax = lcd.plot(kind='barh',x='Word', y='Count',figsize=(5,5),legend=False,color='#000050')\n",
    "ax.xaxis.grid(True)\n",
    "pyplot.rcParams[\"font.family\"] = \"Noto Sans\"\n",
    "pyplot.tight_layout()\n",
    "#pyplot.savefig('word-count2.pdf')\n",
    "#alt.Chart(lcd).mark_bar().encode(x=alt.X('Count',title=\"\"),y=alt.Y('Word',title='',sort=alt.EncodingSortField(\n",
    "#            field=\"yield\",  # The field to use for the sort\n",
    "#            op=\"sum\",  # The operation to run on the field prior to sorting\n",
    "#            order=\"descending\"  # The order to sort in\n",
    "#        ))).properties(width=250,height=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This overview allows us to decide the initial steps in our investigation and some initial conclusions regarding the preference on some easily distinguishable topics. As an example, we notice how a large number (>800) of answers include direct references to the variables, or to the word variable (in singular and plural forms). At this stage, however, we don't know what types of words and themes go along with them. We can count simple tokenized words, as well as words that have been *lemmatized*, that is, their plural forms have been reduced to singular forms, and transformation of verb tenses. In our case, the difference between some tenses do not matter, such as present and past. The lemmmatization process combines *correlate* and *correlated* into a single *correlate* word.\n",
    "\n",
    "As a next step, based on the number of potential nouns in the list, we investigate which concepts are present in the form of nouns and what types of adjectives modify these nouns. We first extract the 20 most common nouns from the list of lemmatized tokens, excluding those in variable *excs* (this can vary, at the moment it's empty) and with length <= 1, keeping them in the *mcn* list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('varb', 852),\n",
       " ('vara', 850),\n",
       " ('variable', 506),\n",
       " ('relationship', 348),\n",
       " ('correlation', 328),\n",
       " ('value', 140),\n",
       " ('data', 139),\n",
       " ('point', 121),\n",
       " ('increase', 112),\n",
       " ('chart', 90),\n",
       " ('trend', 67),\n",
       " ('number', 58),\n",
       " ('line', 54),\n",
       " ('dot', 54),\n",
       " ('graph', 52),\n",
       " ('decrease', 51),\n",
       " ('pattern', 43),\n",
       " ('result', 40),\n",
       " ('outlier', 39),\n",
       " ('middle', 34)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_tags = []\n",
    "mcn = FreqDist()\n",
    "for sent in data.itertuples():\n",
    "    for word,tag in sent.lemmatized:\n",
    "        if (tag.startswith(\"NN\") and (len(word) > 1) and (word not in excs)):\n",
    "            mcn.update([word])\n",
    "mcn.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these evidently overlap with the overall word count, but increase is only considered in its noun form, so it drops down the list. After the proper nouns referring to the variables and the word variable, participants focused on relationship and correlation. Further down the list the word count decreases substantially (the 10th most common noun, chart, occurs 8 times less than the most common ones). \n",
    "\n",
    "Relationship slightly outnumbers correlation -- as the task asked participants to \"describe the relationship\", this is not surprising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.015406162464986"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Question</th>\n",
       "      <th>C0</th>\n",
       "      <th>C2N</th>\n",
       "      <th>C2P</th>\n",
       "      <th>C4N</th>\n",
       "      <th>C4P</th>\n",
       "      <th>C6N</th>\n",
       "      <th>C6P</th>\n",
       "      <th>C8N</th>\n",
       "      <th>C8P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.143750</td>\n",
       "      <td>12.60000</td>\n",
       "      <td>11.762500</td>\n",
       "      <td>11.531250</td>\n",
       "      <td>12.606250</td>\n",
       "      <td>12.643750</td>\n",
       "      <td>12.559748</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>11.832215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.783093</td>\n",
       "      <td>10.65892</td>\n",
       "      <td>9.487819</td>\n",
       "      <td>9.341812</td>\n",
       "      <td>9.792885</td>\n",
       "      <td>10.943737</td>\n",
       "      <td>9.558343</td>\n",
       "      <td>7.976223</td>\n",
       "      <td>7.895776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>57.00000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Question         C0       C2N        C2P        C4N        C4P        C6N  \\\n",
       "mean      11.143750  12.60000  11.762500  11.531250  12.606250  12.643750   \n",
       "std        8.783093  10.65892   9.487819   9.341812   9.792885  10.943737   \n",
       "min        1.000000   1.00000   1.000000   1.000000   1.000000   1.000000   \n",
       "max       43.000000  57.00000  62.000000  55.000000  66.000000  97.000000   \n",
       "\n",
       "Question        C6P        C8N        C8P  \n",
       "mean      12.559748  11.450000  11.832215  \n",
       "std        9.558343   7.976223   7.895776  \n",
       "min        1.000000   1.000000   1.000000  \n",
       "max       66.000000  37.000000  40.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_answer = data.groupby('Question')['lemmatized'].apply(len).mean()\n",
    "data['word_count'] = data.tokenized.apply(len) #.mean()\n",
    "display(data.word_count.mean())\n",
    "#display(data[data['word_count'] == 97].Answer.to_list())\n",
    "data.groupby('Question').describe()['word_count'][['mean','std','min','max']].T #%,'25%','50%','75%']].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjectives\n",
    "\n",
    "As a next step, we look at the words that appear along with common nouns. Of particular interest are the adjectives.\n",
    "\n",
    "For that, we specify bigrams and trigrams filters for pairs of (adjective,nouns). (To limit the number of bigrams, we focus on the list of 20 most common nouns above, excluding the nouns not in that list.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify a filter to capture only adjectives that are going along common nouns (not proper nouns such as VarA and VarB)\n",
    "def bigram_filter(w1,w2):\n",
    "    #print(w1,w2)\n",
    "    return not (((w1[1].startswith(\"JJ\")) and (w2[1] == \"NN\"))\n",
    "                or ((w1[1].startswith(\"JJ\")) and (w2[1] == \"NN\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify a filter to capture only adjectives that are going along common nouns (not proper nouns such as VarA and VarB)\n",
    "def bigram_filter2(w1,w2):\n",
    "    return not (((w1[1] == \"JJ\") and (w2[1] == \"NN\"))\n",
    "                or ((w1[1] == \"JJ\") and (w2[1] == \"NNS\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('positive', 'JJ'), ('correlation', 'NN')), 79),\n",
       " ((('negative', 'JJ'), ('correlation', 'NN')), 72),\n",
       " ((('clear', 'JJ'), ('relationship', 'NN')), 28),\n",
       " ((('positive', 'JJ'), ('relationship', 'NN')), 26),\n",
       " ((('linear', 'JJ'), ('relationship', 'NN')), 22)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = BigramCollocationFinder.from_documents(data['lemmatized'])\n",
    "bigrams.apply_ngram_filter(bigram_filter)\n",
    "#bigrams.apply_ngram_filter(lambda w1,w2: not ((w1[0] in magscale))) and (noun_cat[w2[0]] == 'RELATION' if w2[0] in noun_cat else True)))\n",
    "#bigrams.apply_ngram_filter(lambda w1,w2: not (noun_cat[w2[0]] == 'RELATION' if w2[0] in noun_cat else True))\n",
    "#bigrams.apply_ngram_filter(lambda w1,w2: not (adj_cat[w1[0]] == 'MAGNITUDE' if w1[0] in adj_cat else True))\n",
    "\n",
    "#Convert them to a list so we can sort them by frequency\n",
    "bigram_list = list(bigrams.ngram_fd.items())\n",
    "bigram_list.sort(key=lambda item: item[-1], reverse=True)\n",
    "#for a,b in bigram_list:\n",
    "#    print(a[0][0],a[1][0],b)\n",
    "bigram_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['similar',\n",
       "   'discernible',\n",
       "   'clear',\n",
       "   'real',\n",
       "   'proportional',\n",
       "   'diagonal',\n",
       "   'active',\n",
       "   'good',\n",
       "   'vague',\n",
       "   'positive',\n",
       "   'inversely-proportional',\n",
       "   'predictable',\n",
       "   'linear',\n",
       "   'constant',\n",
       "   'causal',\n",
       "   'direct',\n",
       "   'much',\n",
       "   'slight',\n",
       "   'random',\n",
       "   'moderate',\n",
       "   'strong',\n",
       "   'minimal',\n",
       "   'casual',\n",
       "   'noticeable',\n",
       "   'small',\n",
       "   'little',\n",
       "   'symmetrical',\n",
       "   'inverse',\n",
       "   'particular',\n",
       "   'distinct',\n",
       "   'weak',\n",
       "   'identifiable',\n",
       "   'loose',\n",
       "   'common',\n",
       "   'obvious',\n",
       "   'negative',\n",
       "   'consistent'],\n",
       "  'relationship')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group adjectives by nouns\n",
    "groups = []\n",
    "ngram = sorted(bigram_list,key=lambda item: item[0][1][0])\n",
    "for k, g in groupby(ngram, key=lambda item: item[0][1][0]):\n",
    "    vals = [itemgetter(0)(i) for i in list(g)]\n",
    "    groups.append((list(set([v[0][0] for v in vals])),k))\n",
    "#groups\n",
    "groups.sort(key=lambda t: len(t[0]), reverse=True)\n",
    "#groups\n",
    "fgroups = [element for element in groups if (len(element[0]) >= 1)]\n",
    "fgroups[:1]\n",
    "#print_pairs_na(fgroups,'adj-noun-all.tsv') # This saves the file so we can manually code the nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['variable',\n",
       "   'value',\n",
       "   'b',\n",
       "   'value',\n",
       "   'variable',\n",
       "   'number',\n",
       "   'concentration',\n",
       "   'amount',\n",
       "   'b',\n",
       "   'r',\n",
       "   'point',\n",
       "   'correlation',\n",
       "   'quantity',\n",
       "   'number',\n",
       "   'increase',\n",
       "   'variable',\n",
       "   'frequency',\n",
       "   'density',\n",
       "   'number',\n",
       "   'variability',\n",
       "   'degree',\n",
       "   'end',\n",
       "   'incidence',\n",
       "   'end',\n",
       "   'range'],\n",
       "  'high'),\n",
       " (['end',\n",
       "   'value',\n",
       "   'variable',\n",
       "   'confidence',\n",
       "   'b',\n",
       "   'section',\n",
       "   'incidence',\n",
       "   'scattering',\n",
       "   'amount',\n",
       "   'increase',\n",
       "   'likelihood',\n",
       "   'variable',\n",
       "   'vice',\n",
       "   'point',\n",
       "   'status'],\n",
       "  'low')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group nouns by adjectives\n",
    "groups = []\n",
    "uniquekeys = []\n",
    "ngram = sorted(bigram_list,key=lambda item: item[0][0][0])\n",
    "for k, g in groupby(ngram, key=lambda item: item[0][0][0]):\n",
    "    vals = [itemgetter(0)(i) for i in list(g)]\n",
    "    groups.append(([v[1][0] for v in vals],k))\n",
    "    uniquekeys.append(k)\n",
    "#groups\n",
    "groups.sort(key=lambda t: len(t[0]), reverse=True)\n",
    "#groups\n",
    "fgroups = [element for element in groups if (len(element[0]) >= 1)]\n",
    "fgroups[:2]\n",
    "#print_pairs_na(fgroups,'noun-adj-all.tsv') # This saves the file so we can manually code the adjectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see that participants use a wide range of adjectives to describe correlation and relationship, and these overlap quite a bit. We need to remember that when looking for bigrams, we are not checking if the words are preceded by \"no\" or \"not\". But at this stage we are not looking for the association between bigrams and the answers, so it doesn't really matter.\n",
    "\n",
    "In addition to relationship and correlation, several other concepts appear here: pattern, trend, range, increase, rate, scattering, anomaly/outlier, association, cluster. There are also references to shapes: dot, line, point, graph.\n",
    "\n",
    "In terms of adjectives, for relationship and correlation, participants focused mostly on their magnitude.\n",
    "The adjectives used for pattern refer to how perceptible it was. For trend, people refer to its direction, magnitude and perceptibility. \n",
    "\n",
    "We continue the analysis by expanding into trigrams to look for double adjectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigram_filter(w1,w2,w3):\n",
    "    return not (w1[1].startswith(\"JJ\") and w2[1].startswith(\"JJ\") and w3[1].startswith(\"NN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('weak', 'JJ'), ('positive', 'JJ'), ('correlation', 'NN')), 14),\n",
       " ((('slight', 'JJ'), ('negative', 'JJ'), ('correlation', 'NN')), 13),\n",
       " ((('strong', 'JJ'), ('positive', 'JJ'), ('correlation', 'NN')), 10),\n",
       " ((('slight', 'JJ'), ('positive', 'JJ'), ('correlation', 'NN')), 10),\n",
       " ((('weak', 'JJ'), ('negative', 'JJ'), ('correlation', 'NN')), 9),\n",
       " ((('strong', 'JJ'), ('negative', 'JJ'), ('correlation', 'NN')), 8),\n",
       " ((('strong', 'JJ'), ('positive', 'JJ'), ('relationship', 'NN')), 4),\n",
       " ((('slight', 'JJ'), ('positive', 'JJ'), ('relationship', 'NN')), 4),\n",
       " ((('moderate', 'JJ'), ('negative', 'JJ'), ('relationship', 'NN')), 4),\n",
       " ((('negative', 'JJ'), ('linear', 'JJ'), ('relationship', 'NN')), 4),\n",
       " ((('moderate', 'JJ'), ('positive', 'JJ'), ('relationship', 'NN')), 3),\n",
       " ((('loose', 'JJ'), ('positive', 'JJ'), ('correlation', 'NN')), 3),\n",
       " ((('positive', 'JJ'), ('linear', 'JJ'), ('relationship', 'NN')), 2),\n",
       " ((('low', 'JJ'), ('positive', 'JJ'), ('correlation', 'NN')), 2),\n",
       " ((('mild', 'JJ'), ('direct', 'JJ'), ('relationship', 'NN')), 2),\n",
       " ((('weak', 'JJ'), ('positive', 'JJ'), ('relationship', 'NN')), 2),\n",
       " ((('small', 'JJ'), ('negative', 'JJ'), ('relationship', 'NN')), 2),\n",
       " ((('loose', 'JJ'), ('negative', 'JJ'), ('correlation', 'NN')), 2),\n",
       " ((('low', 'JJ'), ('negative', 'JJ'), ('correlation', 'NN')), 2),\n",
       " ((('weak', 'JJ'), ('negative', 'JJ'), ('relationship', 'NN')), 2),\n",
       " ((('strong', 'JJ'), ('negative', 'JJ'), ('relationship', 'NN')), 2),\n",
       " ((('middling', 'JJ'), ('low', 'JJR'), ('statistic', 'NNS')), 1),\n",
       " ((('strong', 'JJ'), ('one-to-one', 'JJ'), ('correlation', 'NN')), 1),\n",
       " ((('noticeable', 'JJ'), ('positive', 'JJ'), ('relationship', 'NN')), 1),\n",
       " ((('linear', 'JJ'), ('positive', 'JJ'), ('relationship', 'NN')), 1),\n",
       " ((('weak-to-moderate', 'JJ'), ('positive', 'JJ'), ('correlation', 'NN')), 1),\n",
       " ((('strong', 'JJ'), ('positive', 'JJ'), ('association', 'NN')), 1),\n",
       " ((('loose', 'JJ'), ('direct', 'JJ'), ('relationship', 'NN')), 1),\n",
       " ((('diffuse', 'JJ'), ('proportional', 'JJ'), ('relationship', 'NN')), 1),\n",
       " ((('small', 'JJ'), ('positive', 'JJ'), ('correlation', 'NN')), 1),\n",
       " ((('general', 'JJ'), ('positive', 'JJ'), ('correlation', 'NN')), 1),\n",
       " ((('strong', 'JJ'), ('linear', 'JJ'), ('relationship', 'NN')), 1),\n",
       " ((('small', 'JJ'), ('positive', 'JJ'), ('relationship', 'NN')), 1),\n",
       " ((('broad', 'JJ'), ('positive', 'JJ'), ('correlation', 'NN')), 1),\n",
       " ((('slight', 'JJS'), ('positive', 'JJ'), ('correlation', 'NN')), 1),\n",
       " ((('tiny', 'JJ'), ('positive', 'JJ'), ('correlation', 'NN')), 1),\n",
       " ((('more', 'JJR'), ('low', 'JJR'), ('variable', 'NNS')), 1),\n",
       " ((('weak', 'JJ'), ('linear', 'JJ'), ('relationship', 'NN')), 1),\n",
       " ((('weak', 'JJ'), ('strong', 'JJ'), ('correlation', 'NN')), 1),\n",
       " ((('linear', 'JJ'), ('direct', 'JJ'), ('relationship', 'NNS')), 1),\n",
       " ((('loose', 'JJ'), ('linear', 'JJ'), ('relationship', 'NN')), 1),\n",
       " ((('poor', 'JJ'), ('positive', 'JJ'), ('correlation', 'NN')), 1),\n",
       " ((('weak', 'JJ'), ('negative', 'JJ'), ('correlationship', 'NN')), 1),\n",
       " ((('slight', 'JJ'), ('negative', 'JJ'), ('relationship', 'NN')), 1),\n",
       " ((('vague', 'JJ'), ('negative', 'JJ'), ('correlation', 'NN')), 1),\n",
       " ((('diffuse', 'JJ'), ('inverse', 'JJ'), ('relationship', 'NN')), 1),\n",
       " ((('strong-ish', 'JJ'), ('negative', 'JJ'), ('association', 'NN')), 1),\n",
       " ((('weak', 'JJ'), ('inverse', 'JJ'), ('correlation', 'NN')), 1),\n",
       " ((('downward', 'JJ'), ('diagonal', 'JJ'), ('relationship', 'NN')), 1),\n",
       " ((('poor', 'JJ'), ('inverse', 'JJ'), ('correlation', 'NN')), 1),\n",
       " ((('rough', 'JJ'), ('negative', 'JJ'), ('correlation', 'NN')), 1),\n",
       " ((('moderate', 'JJ'), ('negative', 'JJ'), ('correlation', 'NN')), 1),\n",
       " ((('consistent', 'JJ'), ('negative', 'JJ'), ('correlation', 'NN')), 1),\n",
       " ((('clear', 'JJ'), ('negative', 'JJ'), ('correlation', 'NN')), 1),\n",
       " ((('general', 'JJ'), ('inverse', 'JJ'), ('relationship', 'NN')), 1),\n",
       " ((('inverse', 'JJ'), ('linear', 'JJ'), ('relationship', 'NN')), 1),\n",
       " ((('medium-strong', 'JJ'), ('negative', 'JJ'), ('relationship', 'NN')), 1),\n",
       " ((('noticeable', 'JJ'), ('negative', 'JJ'), ('correlation', 'NN')), 1),\n",
       " ((('linear', 'JJ'), ('negative', 'JJ'), ('relationship', 'NN')), 1)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams = TrigramCollocationFinder.from_documents(data['lemmatized'].tolist())\n",
    "trigrams.apply_ngram_filter(trigram_filter)\n",
    "#trigrams.apply_ngram_filter(lambda w1,w2,w3: not ((w1[0] in magscale) and (noun_cat[w3[0]] == 'RELATION' if w3[0] in noun_cat else True)))\n",
    "trigrams.apply_ngram_filter(lambda w1,w2,w3: not (noun_cat[w3[0]] == 'RELATION' if w3[0] in noun_cat else True))\n",
    "#trigrams.apply_ngram_filter(lambda w1,w2,w3: not (noun_cat[w1[0]] == 'MAGNITUDE' if w3[0] in noun_cat else True))\n",
    "trigram = list(trigrams.ngram_fd.items())\n",
    "trigram.sort(key=lambda item: item[-1], reverse=True)\n",
    "trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the bigrams, there is not a great difference in terms of which adjectives appear, however, we can notice that there is a long tail of trigrams with only a single occurrence. We can now compute the overall occurrences of adjectives used in collocations in the whole data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bjj = [(jj[0][0][0],jj[1]) for jj in bigrams.ngram_fd.items() if jj[0][0][1].startswith(\"JJ\")]\n",
    "bigram_jj_nocount = [jj[0][0][0] for jj in bigrams.ngram_fd.items() if jj[0][0][1].startswith(\"JJ\")]\n",
    "tjj = [(jj[0][0][0],jj[1]) for jj in trigrams.ngram_fd.items() if (jj[0][0][0] not in bjj) and (jj[0][0][1].startswith(\"JJ\"))]\n",
    "trigram_jj_nocount = [jj[0][0][0] for jj in trigrams.ngram_fd.items() if (jj[0][0][0] not in bjj) and (jj[0][0][1].startswith(\"JJ\"))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn = [(nn[0][1][0],nn[1]) for nn in bigrams.ngram_fd.items() if nn[0][1][1].startswith(\"NN\")]\n",
    "bigram_nn_nocount = [jj[0][1][0] for jj in bigrams.ngram_fd.items() if jj[0][1][1].startswith(\"NN\")]\n",
    "tnn = [(jj[0][1][0],jj[1]) for jj in trigrams.ngram_fd.items() if (jj[0][1][0] not in bjj) and (jj[0][1][1].startswith(\"NN\"))]\n",
    "trigram_nn_nocount = [jj[0][1][0] for jj in trigrams.ngram_fd.items() if (jj[0][1][0] not in bjj) and (jj[0][1][1].startswith(\"NN\"))]\n",
    "#bjj.remove('positive')\n",
    "#bjj.remove('negative')\n",
    "#bjj.remove('direct')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('positive', 110),\n",
       " ('negative', 94),\n",
       " ('clear', 57),\n",
       " ('high', 53),\n",
       " ('strong', 49),\n",
       " ('slight', 48),\n",
       " ('weak', 46),\n",
       " ('low', 40),\n",
       " ('linear', 38),\n",
       " ('obvious', 21),\n",
       " ('loose', 21),\n",
       " ('little', 19),\n",
       " ('direct', 17),\n",
       " ('diagonal', 16),\n",
       " ('wide', 13),\n",
       " ('general', 12),\n",
       " ('random', 12),\n",
       " ('same', 11),\n",
       " ('steady', 11),\n",
       " ('inverse', 11)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjs = set(bigram_nn_nocount + trigram_nn_nocount)\n",
    "adjs = list(adjs)\n",
    "#adjs.remove('positive')\n",
    "#adjs.remove('negative')\n",
    "_C = {}\n",
    "for l in bjj, tjj:\n",
    "    for d in l:\n",
    "        _C[d[0]] = int(d[1]) +int(_C.get(d[0], 0))\n",
    "\n",
    "adjs2 = [(k,c) for (k, c) in _C.items()]\n",
    "#dict(adjs2)\n",
    "#print(list(filter(lambda x: x[1] > 1,adjs2))[:10])\n",
    "adjs2 = sorted(adjs2,key=lambda x: -x[1])\n",
    "#for a in adjs2:\n",
    "#    print(sorted(adj))\n",
    "#print(adjs2[:10])\n",
    "adjs2[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('correlation', 243),\n",
       " ('relationship', 185),\n",
       " ('trend', 31),\n",
       " ('variable', 29),\n",
       " ('pattern', 27),\n",
       " ('value', 19),\n",
       " ('line', 16),\n",
       " ('range', 16),\n",
       " ('increase', 15),\n",
       " ('spread', 14),\n",
       " ('rate', 13),\n",
       " ('b', 9),\n",
       " ('part', 9),\n",
       " ('scattering', 9),\n",
       " ('end', 9),\n",
       " ('sloping', 8),\n",
       " ('amount', 8),\n",
       " ('association', 7),\n",
       " ('cluster', 7),\n",
       " ('number', 6)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = set(bigram_nn_nocount + trigram_nn_nocount)\n",
    "nouns = list(nouns)\n",
    "#adjs.remove('positive')\n",
    "#adjs.remove('negative')\n",
    "_C = {}\n",
    "for l in bnn, tnn:\n",
    "    for d in l:\n",
    "        _C[d[0]] = int(d[1]) +int(_C.get(d[0], 0))\n",
    "\n",
    "nouns2 = [(k,c) for (k, c) in _C.items()]\n",
    "dict(nouns2)\n",
    "#print(list(filter(lambda x: x[1] > 1,adjs2))[:10])\n",
    "nouns2 = sorted(nouns2,key=lambda x: -x[1])\n",
    "#for a in adjs2:\n",
    "#    print(sorted(adj))\n",
    "#print(adjs2[:10])\n",
    "nouns2[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjective use per correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that gets all the adjectives that go along with the filterWords, returning them as tuples\n",
    "#Dependencies:\n",
    "def get_all_adjs_as_tuple(ls,filterWords):\n",
    "    \n",
    "    finder = BigramCollocationFinder.from_documents(ls)\n",
    "    finder.apply_ngram_filter(bigram_filter)\n",
    "#    finder.apply_ngram_filter(lambda w1,w2: not (w2[0] in mcn))\n",
    "    if (len(filterWords) > 0):\n",
    "        finder.apply_ngram_filter(lambda w1, w2: not (w2[0] in filterWords))\n",
    "    bigram_adjs = [(jj[0][0][0],jj[1]) for jj in finder.ngram_fd.items() if jj[0][0][1].startswith(\"JJ\")]\n",
    "    \n",
    "    trigrams = TrigramCollocationFinder.from_documents(ls)\n",
    "    trigrams.apply_ngram_filter(trigram_filter)\n",
    "    if (len(filterWords) > 0):\n",
    "        trigrams.apply_ngram_filter(lambda w1, w2, w3: not ((w2[0] in filterWords) or (w3[0] in filterWords)))\n",
    "    trigram_adjs = [(jj[0][0][0],jj[1]) for jj in trigrams.ngram_fd.items() if (jj[0][0][0] not in bjj) and (jj[0][0][1].startswith(\"JJ\"))]\n",
    "    \n",
    "    _C = {}\n",
    "    for l in bigram_adjs, trigram_adjs:\n",
    "        for d in l:\n",
    "            _C[d[0]] = int(d[1]) +int(_C.get(d[0], 0))\n",
    "\n",
    "    adjs2 = {(k,c) for (k, c) in _C.items()}\n",
    "    return adjs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that gets all the adjectives that go along with the filterWords, returning them as tuples\n",
    "#Dependencies:\n",
    "def get_nouns_tuple(ls,filterWords):\n",
    "    \n",
    "    finder = BigramCollocationFinder.from_documents(ls)\n",
    "    finder.apply_ngram_filter(bigram_filter)\n",
    "   # finder.apply_ngram_filter(lambda w1,w2: (w2[1] == \"NNP\"))\n",
    "    bigram_adjs = [(jj[0][1][0],jj[1]) for jj in finder.ngram_fd.items() if jj[0][1][1].startswith(\"NN\")]\n",
    "    \n",
    "    trigrams = TrigramCollocationFinder.from_documents(ls)\n",
    "    trigrams.apply_ngram_filter(trigram_filter)\n",
    "    trigram_adjs = [(jj[0][0][0],jj[1]) for jj in trigrams.ngram_fd.items() if (jj[0][0][0] not in bjj) and (jj[0][0][1].startswith(\"JJ\"))]\n",
    "    \n",
    "    _C = {}\n",
    "    for l in bigram_adjs, trigram_adjs:\n",
    "        for d in l:\n",
    "            _C[d[0]] = int(d[1]) +int(_C.get(d[0], 0))\n",
    "\n",
    "    adjs2 = {(k,c) for (k, c) in _C.items()}\n",
    "    return adjs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that gets all the adjectives that go along with the filterWords\n",
    "#Dependencies:\n",
    "def get_all_adjs(ls,filterWords):\n",
    "    mcn = FreqDist()\n",
    "    #print(ls)\n",
    "    for sent in ls:\n",
    "        for word,tag in sent:\n",
    "            if (tag.startswith(\"NN\") and (len(word) > 1)):\n",
    "                mcn.update([word])\n",
    "    finder = BigramCollocationFinder.from_documents(ls)\n",
    "    finder.apply_ngram_filter(bigram_filter)\n",
    "#    finder.apply_ngram_filter(lambda w1,w2: not (w2[0] in mcn))\n",
    "    if (len(filterWords) > 0):\n",
    "        finder.apply_ngram_filter(lambda w1, w2: not (w2[0] in filterWords))\n",
    "    bigram_adjs = [(jj[0][0][0],jj[1]) for jj in finder.ngram_fd.items() if jj[0][0][1].startswith(\"JJ\")]\n",
    "    trigrams = TrigramCollocationFinder.from_documents(ls)\n",
    "    trigrams.apply_ngram_filter(trigram_filter)\n",
    "    if (len(filterWords) > 0):\n",
    "        trigrams.apply_ngram_filter(lambda w1, w2, w3: not ((w2[0] in filterWords) or (w3[0] in filterWords)))\n",
    "    trigram_adjs = [(jj[0][0][0],jj[1]) for jj in trigrams.ngram_fd.items() if (jj[0][0][0] not in bjj) and (jj[0][0][1].startswith(\"JJ\"))]\n",
    "    _C = {}\n",
    "    for l in bigram_adjs, trigram_adjs:\n",
    "        for d in l:\n",
    "            _C[d[0]] = int(d[1]) +int(_C.get(d[0], 0))\n",
    "\n",
    "    adjs2 = {k: c for (k, c) in _C.items()}\n",
    "    return adjs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gets lemmatized sentences and group them by question\n",
    "adjs_by_q_dict = {}\n",
    "adjs_by_q = {}\n",
    "for q in Qs:\n",
    "    lq = data[data['Question'] == q]['lemmatized']\n",
    "    fw = ['correlation','relationship']\n",
    "    adjs_by_q[q] = get_all_adjs_as_tuple(lq,[])\n",
    "    adjs_by_q_dict[q] = get_all_adjs(lq,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = pyplot.subplots(nrows=3, ncols=3,figsize=(24,24))\n",
    "fig.subplots_adjust(wspace=1,hspace=1)\n",
    "x = 0\n",
    "for k in adjs_by_q:\n",
    "    #display(sorted(adjs_by_q[k],key=lambda x: -x[1])[:10])\n",
    "#    print(k)\n",
    " #   for w in sorted(faq[k],key=lambda x: -x[1]):\n",
    " #       print(w[0]+'\\t'+str(w[1]))\n",
    " #   print (\",\")\n",
    "    lcd2 = pd.DataFrame(list(adjs_by_q[k]),columns=['Word','Count'])\n",
    "    lcd2 = lcd2.sort_values(by=['Count'],axis=0,ascending=True)\n",
    "    ax = lcd2.tail(10).plot(kind='barh',x='Word', y='Count',title=k,figsize=(9,9),legend=False,ax=axes[x // 3,x % 3])\n",
    "    x = x +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': [32, 30, 26, 14, 1, 6, 0, 0, 1],\n",
       " 'negative': [0, 0, 1, 0, 0, 6, 18, 33, 36],\n",
       " 'clear': [5, 0, 7, 9, 11, 8, 10, 0, 9],\n",
       " 'high': [6, 9, 6, 4, 4, 3, 3, 7, 14],\n",
       " 'strong': [17, 7, 3, 3, 2, 2, 1, 3, 13],\n",
       " 'slight': [0, 8, 10, 9, 0, 1, 12, 7, 2],\n",
       " 'weak': [2, 5, 9, 7, 1, 7, 6, 8, 1],\n",
       " 'low': [1, 3, 6, 4, 2, 4, 2, 8, 10],\n",
       " 'linear': [13, 3, 4, 1, 1, 5, 1, 3, 8],\n",
       " 'obvious': [1, 1, 3, 2, 4, 4, 6, 0, 0],\n",
       " 'loose': [1, 5, 4, 1, 0, 2, 4, 4, 0],\n",
       " 'little': [1, 0, 1, 2, 3, 9, 3, 0, 0],\n",
       " 'direct': [3, 3, 1, 5, 1, 2, 1, 0, 1],\n",
       " 'diagonal': [4, 3, 0, 0, 0, 1, 1, 1, 6],\n",
       " 'wide': [0, 1, 1, 2, 2, 0, 4, 3, 0],\n",
       " 'general': [1, 4, 5, 2, 0, 0, 1, 3, 1],\n",
       " 'random': [0, 0, 3, 2, 4, 1, 2, 0, 0],\n",
       " 'same': [2, 1, 3, 1, 1, 2, 0, 1, 0],\n",
       " 'steady': [2, 2, 1, 2, 0, 0, 0, 2, 3],\n",
       " 'inverse': [0, 0, 0, 1, 0, 0, 1, 4, 5]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aCounts = {}\n",
    "for adjective,count in adjs2[:20]:   \n",
    "    aCounts[adjective] = []\n",
    "    for q in adjs_by_q_dict:        \n",
    "        if adjective in adjs_by_q_dict[q]:\n",
    "            aCounts[adjective].append(adjs_by_q_dict[q][adjective])\n",
    "        else:\n",
    "            aCounts[adjective].append(0)\n",
    "display(aCounts)\n",
    "#print('Word\\t-8\\t-6\\t-4\\t-2\\t0\\t2\\t4\\t6\\t8')\n",
    "#for k in aCounts:\n",
    "#    print(k,'\\t','\\t'.join(map(str, aCounts[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for k in adjs_by_q:\n",
    "    df = pd.concat([pd.DataFrame(sorted(adjs_by_q[k],key=lambda x: -x[1])[:10]),df],axis=1,join='outer')\n",
    "#    display(sorted(adjs_by_q[k],key=lambda x: -x[1])[:10])\n",
    "df.to_csv('adj_by_corr.csv')\n",
    "#df_adj_count = pd.DataFrame(adjs_by_q_dict).T.reset_index().melt(id_vars='index',var_name='Word',value_name='Count')\n",
    "#alt.Chart(df_adj_count).mark_line().encode(x='index:O',y='Count:N',color='Word:O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>36</td>\n",
       "      <td>negative</td>\n",
       "      <td>33</td>\n",
       "      <td>negative</td>\n",
       "      <td>18</td>\n",
       "      <td>little</td>\n",
       "      <td>9</td>\n",
       "      <td>clear</td>\n",
       "      <td>11</td>\n",
       "      <td>positive</td>\n",
       "      <td>14</td>\n",
       "      <td>positive</td>\n",
       "      <td>26</td>\n",
       "      <td>positive</td>\n",
       "      <td>30</td>\n",
       "      <td>positive</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>14</td>\n",
       "      <td>low</td>\n",
       "      <td>8</td>\n",
       "      <td>slight</td>\n",
       "      <td>12</td>\n",
       "      <td>clear</td>\n",
       "      <td>8</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>clear</td>\n",
       "      <td>9</td>\n",
       "      <td>slight</td>\n",
       "      <td>10</td>\n",
       "      <td>high</td>\n",
       "      <td>9</td>\n",
       "      <td>strong</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strong</td>\n",
       "      <td>13</td>\n",
       "      <td>weak</td>\n",
       "      <td>8</td>\n",
       "      <td>clear</td>\n",
       "      <td>10</td>\n",
       "      <td>weak</td>\n",
       "      <td>7</td>\n",
       "      <td>high</td>\n",
       "      <td>4</td>\n",
       "      <td>slight</td>\n",
       "      <td>9</td>\n",
       "      <td>weak</td>\n",
       "      <td>9</td>\n",
       "      <td>slight</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>low</td>\n",
       "      <td>10</td>\n",
       "      <td>high</td>\n",
       "      <td>7</td>\n",
       "      <td>weak</td>\n",
       "      <td>6</td>\n",
       "      <td>positive</td>\n",
       "      <td>6</td>\n",
       "      <td>obvious</td>\n",
       "      <td>4</td>\n",
       "      <td>weak</td>\n",
       "      <td>7</td>\n",
       "      <td>clear</td>\n",
       "      <td>7</td>\n",
       "      <td>strong</td>\n",
       "      <td>7</td>\n",
       "      <td>high</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clear</td>\n",
       "      <td>9</td>\n",
       "      <td>slight</td>\n",
       "      <td>7</td>\n",
       "      <td>obvious</td>\n",
       "      <td>6</td>\n",
       "      <td>negative</td>\n",
       "      <td>6</td>\n",
       "      <td>discernible</td>\n",
       "      <td>3</td>\n",
       "      <td>direct</td>\n",
       "      <td>5</td>\n",
       "      <td>high</td>\n",
       "      <td>6</td>\n",
       "      <td>loose</td>\n",
       "      <td>5</td>\n",
       "      <td>clear</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>linear</td>\n",
       "      <td>8</td>\n",
       "      <td>downward</td>\n",
       "      <td>4</td>\n",
       "      <td>wide</td>\n",
       "      <td>4</td>\n",
       "      <td>linear</td>\n",
       "      <td>5</td>\n",
       "      <td>little</td>\n",
       "      <td>3</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "      <td>6</td>\n",
       "      <td>weak</td>\n",
       "      <td>5</td>\n",
       "      <td>diagonal</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>diagonal</td>\n",
       "      <td>6</td>\n",
       "      <td>inverse</td>\n",
       "      <td>4</td>\n",
       "      <td>loose</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>strong</td>\n",
       "      <td>2</td>\n",
       "      <td>high</td>\n",
       "      <td>4</td>\n",
       "      <td>general</td>\n",
       "      <td>5</td>\n",
       "      <td>general</td>\n",
       "      <td>4</td>\n",
       "      <td>similar</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>inverse</td>\n",
       "      <td>5</td>\n",
       "      <td>loose</td>\n",
       "      <td>4</td>\n",
       "      <td>vague</td>\n",
       "      <td>3</td>\n",
       "      <td>obvious</td>\n",
       "      <td>4</td>\n",
       "      <td>wide</td>\n",
       "      <td>2</td>\n",
       "      <td>strong</td>\n",
       "      <td>3</td>\n",
       "      <td>linear</td>\n",
       "      <td>4</td>\n",
       "      <td>diagonal</td>\n",
       "      <td>3</td>\n",
       "      <td>direct</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>downward</td>\n",
       "      <td>5</td>\n",
       "      <td>strong</td>\n",
       "      <td>3</td>\n",
       "      <td>scattered</td>\n",
       "      <td>3</td>\n",
       "      <td>real</td>\n",
       "      <td>4</td>\n",
       "      <td>much</td>\n",
       "      <td>2</td>\n",
       "      <td>little</td>\n",
       "      <td>2</td>\n",
       "      <td>loose</td>\n",
       "      <td>4</td>\n",
       "      <td>consistent</td>\n",
       "      <td>3</td>\n",
       "      <td>most</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>steady</td>\n",
       "      <td>3</td>\n",
       "      <td>linear</td>\n",
       "      <td>3</td>\n",
       "      <td>little</td>\n",
       "      <td>3</td>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "      <td>median</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>strong</td>\n",
       "      <td>3</td>\n",
       "      <td>linear</td>\n",
       "      <td>3</td>\n",
       "      <td>weak</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0   1         0   1          0   1         0  1            0   1  \\\n",
       "0  negative  36  negative  33   negative  18    little  9        clear  11   \n",
       "1      high  14       low   8     slight  12     clear  8       random   4   \n",
       "2    strong  13      weak   8      clear  10      weak  7         high   4   \n",
       "3       low  10      high   7       weak   6  positive  6      obvious   4   \n",
       "4     clear   9    slight   7    obvious   6  negative  6  discernible   3   \n",
       "5    linear   8  downward   4       wide   4    linear  5       little   3   \n",
       "6  diagonal   6   inverse   4      loose   4       low  4       strong   2   \n",
       "7   inverse   5     loose   4      vague   3   obvious  4         wide   2   \n",
       "8  downward   5    strong   3  scattered   3      real  4         much   2   \n",
       "9    steady   3    linear   3     little   3      high  3       median   2   \n",
       "\n",
       "          0   1         0   1           0   1         0   1  \n",
       "0  positive  14  positive  26    positive  30  positive  32  \n",
       "1     clear   9    slight  10        high   9    strong  17  \n",
       "2    slight   9      weak   9      slight   8    linear  13  \n",
       "3      weak   7     clear   7      strong   7      high   6  \n",
       "4    direct   5      high   6       loose   5     clear   5  \n",
       "5       low   4       low   6        weak   5  diagonal   4  \n",
       "6      high   4   general   5     general   4   similar   3  \n",
       "7    strong   3    linear   4    diagonal   3    direct   3  \n",
       "8    little   2     loose   4  consistent   3      most   2  \n",
       "9    random   2    strong   3      linear   3      weak   2  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verbs and Adverbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the same methods that we used to analyse adjectives and nouns to look for verbs and adverbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adverb_filter(w1,w2):\n",
    "# return not ( ((w1[1].startswith(\"RB\")) and (w2[1].startswith(\"VB\"))) \n",
    " return not (((w1[1].startswith(\"RB\")) and (w2[1].startswith(\"VB\"))))\n",
    "#                or ((w1[1].startswith(\"RB\")) and (w2[1].startswith(\"JJ\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adverb_trigram_filter(w1,w2,w3):\n",
    "# return not ( ((w1[1].startswith(\"RB\")) and (w2[1].startswith(\"VB\"))) \n",
    " return not ((w2[1].startswith(\"RB\")) and (w3[1].startswith(\"VB\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('so', 'RB'), ('do', 'VBZ')), 42),\n",
       " ((('there', 'RB'), ('appear', 'VBZ')), 42),\n",
       " ((('there', 'RB'), ('seem', 'VBZ')), 38),\n",
       " ((('very', 'RB'), ('scatter', 'VBN')), 20),\n",
       " ((('not', 'RB'), ('appear', 'VB')), 16),\n",
       " ((('also', 'RB'), ('increase', 'VBZ')), 13),\n",
       " ((('there', 'RB'), ('do', 'VBZ')), 13),\n",
       " ((('there', 'RB'), ('s', 'VBZ')), 8),\n",
       " ((('not', 'RB'), ('seem', 'VB')), 7),\n",
       " ((('evenly', 'RB'), ('distribute', 'VBN')), 6),\n",
       " ((('widely', 'RB'), ('spread', 'VBN')), 6),\n",
       " ((('even', 'RB'), ('spread', 'VBN')), 5),\n",
       " ((('fairly', 'RB'), ('scatter', 'VBN')), 5),\n",
       " ((('evenly', 'RB'), ('spread', 'VBN')), 5),\n",
       " ((('quite', 'RB'), ('scatter', 'VBN')), 5),\n",
       " ((('so', 'RB'), ('be', 'VBZ')), 4),\n",
       " ((('also', 'RB'), ('decrease', 'VBZ')), 4),\n",
       " ((('widely', 'RB'), ('scatter', 'VBN')), 3),\n",
       " ((('not', 'RB'), ('see', 'VB')), 3),\n",
       " ((('evenly', 'RB'), ('scatter', 'VBN')), 3),\n",
       " ((('widely', 'RB'), ('distribute', 'VBN')), 2),\n",
       " ((('always', 'RB'), ('have', 'VBP')), 2),\n",
       " ((('too', 'RB'), ('do', 'VBZ')), 2),\n",
       " ((('generally', 'RB'), ('increase', 'VBZ')), 2),\n",
       " ((('generally', 'RB'), ('do', 'VBZ')), 2),\n",
       " ((('loosely', 'RB'), ('indicate', 'VBZ')), 2),\n",
       " ((('more', 'RBR'), ('scatter', 'VBN')), 2),\n",
       " ((('well', 'RB'), ('scatter', 'VBN')), 2),\n",
       " ((('also', 'RB'), ('be', 'VB')), 2),\n",
       " ((('here', 'RB'), ('be', 'VBZ')), 2),\n",
       " ((('not', 'RB'), ('have', 'VB')), 2),\n",
       " ((('here', 'RB'), ('be', 'VBP')), 2),\n",
       " ((('tightly', 'RB'), ('correlate', 'VBN')), 2),\n",
       " ((('always', 'RB'), ('be', 'VB')), 2),\n",
       " ((('here', 'RB'), ('suggesting', 'VBG')), 2),\n",
       " ((('equally', 'RB'), ('distribute', 'VBN')), 2),\n",
       " ((('extremely', 'RB'), ('scatter', 'VBN')), 2),\n",
       " ((('not', 'RB'), ('feel', 'VB')), 2),\n",
       " ((('also', 'RB'), ('show', 'VBZ')), 2),\n",
       " ((('usually', 'RB'), ('lead', 'VBZ')), 2),\n",
       " ((('well', 'RB'), ('correlate', 'VBN')), 1),\n",
       " ((('generally', 'RB'), ('link', 'VBN')), 1),\n",
       " ((('diagonally', 'RB'), ('upwards', 'VBZ')), 1),\n",
       " ((('too', 'RB'), ('showing', 'VBG')), 1),\n",
       " ((('also', 'RB'), ('get', 'VBP')), 1),\n",
       " ((('almost', 'RB'), ('form', 'VBP')), 1),\n",
       " ((('typically', 'RB'), ('indicate', 'VBZ')), 1),\n",
       " ((('again', 'RB'), ('be', 'VB')), 1),\n",
       " ((('most', 'RBS'), ('define', 'VBN')), 1),\n",
       " ((('also', 'RB'), ('correlate', 'VBZ')), 1),\n",
       " ((('mainly', 'RB'), ('congest', 'VBN')), 1),\n",
       " ((('very', 'RB'), ('lose', 'VB')), 1),\n",
       " ((('randomly', 'RB'), ('distribute', 'VBN')), 1),\n",
       " ((('so', 'RB'), ('do', 'VB')), 1),\n",
       " ((('not', 'RB'), ('close', 'VB')), 1),\n",
       " ((('again', 'RB'), ('appear', 'VBP')), 1),\n",
       " ((('also', 'RB'), ('seem', 'VBP')), 1),\n",
       " ((('also', 'RB'), ('tend', 'VBP')), 1),\n",
       " ((('not', 'RB'), ('conform', 'VB')), 1),\n",
       " ((('here', 'RB'), ('gather', 'VBZ')), 1),\n",
       " ((('closely', 'RB'), ('link', 'VBN')), 1),\n",
       " ((('linearly', 'RB'), ('relate', 'VBN')), 1),\n",
       " ((('also', 'RB'), ('appear', 'VBZ')), 1),\n",
       " ((('loosely', 'RB'), ('link', 'VBN')), 1),\n",
       " ((('randomly', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('not', 'RB'), ('being', 'VBG')), 1),\n",
       " ((('yet', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('slightly', 'RB'), ('correlate', 'VBD')), 1),\n",
       " ((('generally', 'RB'), ('centralize', 'VBN')), 1),\n",
       " ((('mostly', 'RB'), ('situate', 'VBN')), 1),\n",
       " ((('here', 'RB'), ('look', 'VBZ')), 1),\n",
       " ((('not', 'RB'), ('surpassing', 'VBG')), 1),\n",
       " ((('not', 'RB'), ('be', 'VB')), 1),\n",
       " ((('less', 'RBR'), ('scatter', 'VBN')), 1),\n",
       " ((('broadly', 'RB'), ('distribute', 'VBN')), 1),\n",
       " ((('there', 'RB'), ('isnt', 'VB')), 1),\n",
       " ((('closely', 'RB'), ('connect', 'VBN')), 1),\n",
       " ((('mostly', 'RB'), ('look', 'VBZ')), 1),\n",
       " ((('more', 'RBR'), ('match', 'VBN')), 1),\n",
       " ((('randomly', 'RB'), ('place', 'VBN')), 1),\n",
       " ((('so', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('very', 'RB'), ('spead', 'VBN')), 1),\n",
       " ((('not', 'RB'), ('look', 'VB')), 1),\n",
       " ((('probably', 'RB'), ('be', 'VB')), 1),\n",
       " ((('heavily', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('slightly', 'RB'), ('increase', 'VBZ')), 1),\n",
       " ((('therefore', 'RB'), ('do', 'VBP')), 1),\n",
       " ((('negatively', 'RB'), ('correlate', 'VBN')), 1),\n",
       " ((('greatly', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('then', 'RB'), ('decrease', 'VBZ')), 1),\n",
       " ((('widely', 'RB'), ('space', 'VBN')), 1),\n",
       " ((('there', 'RB'), ('isn', 'VBP')), 1),\n",
       " ((('even', 'RB'), ('scattering', 'VBG')), 1),\n",
       " ((('too', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('very', 'RB'), ('vary', 'VBN')), 1),\n",
       " ((('generally', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('closely', 'RB'), ('associate', 'VBN')), 1),\n",
       " ((('only', 'RB'), ('appear', 'VBZ')), 1),\n",
       " ((('brightly', 'RB'), ('light', 'VBN')), 1),\n",
       " ((('roughly', 'RB'), ('increase', 'VB')), 1),\n",
       " ((('then', 'RB'), ('be', 'VBZ')), 1),\n",
       " ((('consistently', 'RB'), ('rise', 'VBZ')), 1),\n",
       " ((('again', 'RB'), ('be', 'VBZ')), 1),\n",
       " ((('almost', 'RB'), ('make', 'VBZ')), 1),\n",
       " ((('here', 'RB'), ('seem', 'VBZ')), 1),\n",
       " ((('only', 'RB'), ('indicate', 'VBN')), 1),\n",
       " ((('generally', 'RB'), ('group', 'VBN')), 1),\n",
       " ((('quite', 'RB'), ('spread', 'VBN')), 1),\n",
       " ((('equally', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('evenly', 'RB'), ('place', 'VBN')), 1),\n",
       " ((('more', 'RBR'), ('focus', 'VBN')), 1),\n",
       " ((('rather', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('almost', 'RB'), ('appear', 'VBZ')), 1),\n",
       " ((('fairly', 'RB'), ('link', 'VBN')), 1),\n",
       " ((('somewhat', 'RB'), ('correlate', 'VB')), 1),\n",
       " ((('well', 'RB'), ('distribute', 'VBN')), 1),\n",
       " ((('not', 'RB'), ('showing', 'VBG')), 1),\n",
       " ((('possibly', 'RB'), ('approximate', 'VBN')), 1),\n",
       " ((('here', 'RB'), ('have', 'VBZ')), 1),\n",
       " ((('somewhat', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('easily', 'RB'), ('be', 'VB')), 1),\n",
       " ((('usually', 'RB'), ('mean', 'VBZ')), 1),\n",
       " ((('then', 'RB'), ('drop', 'VB')), 1),\n",
       " ((('steadily', 'RB'), ('decreasing', 'VBG')), 1),\n",
       " ((('downward', 'RB'), ('look', 'VBZ')), 1),\n",
       " ((('generally', 'RB'), ('indicate', 'VBZ')), 1),\n",
       " ((('still', 'RB'), ('show', 'VBP')), 1),\n",
       " ((('clearly', 'RB'), ('decrease', 'VBZ')), 1),\n",
       " ((('positively', 'RB'), ('correlate', 'VBN')), 1),\n",
       " ((('again', 'RB'), ('seem', 'VBZ')), 1),\n",
       " ((('downward', 'RB'), ('sloping', 'VBG')), 1)]"
      ]
     },
     "execution_count": 973,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = BigramCollocationFinder.from_documents(data['lemmatized'].tolist())\n",
    "#bigrams.apply_ngram_filter(lambda w1,w2: not ((w2[0] in mcn)))\n",
    "bigrams.apply_ngram_filter(adverb_filter)\n",
    "#finder.apply_ngram_filter(lambda w1, w2: not ((w2[0] == \"relationship\") or (w2[0] == \"correlation\")))\n",
    "#bigrams.apply_freq_filter(2)\n",
    "\n",
    "#Convert them to a list so we can sort them by frequency\n",
    "adverb_bigram_list = list(bigrams.ngram_fd.items())\n",
    "adverb_bigram_list.sort(key=lambda item: item[-1], reverse=True)\n",
    "#for a,b in bigram_list:\n",
    "#    print(a[0][0],a[1][0],b)\n",
    "adverb_bigram_list\n",
    "#print_pairs_na(adverb_bigram_list,'adverbs.csv') # Save the list to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['greatly',\n",
       "   'well',\n",
       "   'fairly',\n",
       "   'rather',\n",
       "   'somewhat',\n",
       "   'yet',\n",
       "   'widely',\n",
       "   'less',\n",
       "   'equally',\n",
       "   'heavily',\n",
       "   'so',\n",
       "   'randomly',\n",
       "   'too',\n",
       "   'generally',\n",
       "   'evenly',\n",
       "   'very',\n",
       "   'more',\n",
       "   'extremely',\n",
       "   'quite'],\n",
       "  'scatter')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group verbs by adverbs\n",
    "groups = []\n",
    "uniquekeys = []\n",
    "ngram = sorted(adverb_bigram_list,key=lambda item: item[0][1][0])\n",
    "for k, g in groupby(ngram, key=lambda item: item[0][1][0]):\n",
    "    vals = [itemgetter(0)(i) for i in list(g)]\n",
    "    groups.append((list(set([v[0][0] for v in vals])),k))\n",
    "    uniquekeys.append(k)\n",
    "#groups\n",
    "groups.sort(key=lambda t: len(t[0]), reverse=True)\n",
    "#groups\n",
    "fgroups = [element for element in groups if (len(element[0]) >= 1)]\n",
    "fgroups[:1]\n",
    "#print_pairs_na(fgroups,'verbs.tsv') # Save the list to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('increase', 'VBZ'), ('so', 'RB'), ('do', 'VBZ')), 35),\n",
       " ((('varb', 'NNP'), ('also', 'RB'), ('increase', 'VBZ')), 12),\n",
       " ((('do', 'VBZ'), ('not', 'RB'), ('appear', 'VB')), 12),\n",
       " ((('look', 'VBZ'), ('very', 'RB'), ('scatter', 'VBN')), 5),\n",
       " ((('do', 'VBZ'), ('not', 'RB'), ('seem', 'VB')), 4),\n",
       " ((('do', 'VBP'), ('not', 'RB'), ('appear', 'VB')), 4),\n",
       " ((('varb', 'NNP'), ('also', 'RB'), ('decrease', 'VBZ')), 4),\n",
       " ((('increase', 'NNS'), ('so', 'RB'), ('do', 'VBZ')), 3),\n",
       " ((('be', 'VBP'), ('widely', 'RB'), ('spread', 'VBN')), 3),\n",
       " ((('be', 'VBZ'), ('very', 'RB'), ('scatter', 'VBN')), 3),\n",
       " ((('be', 'VBP'), ('quite', 'RB'), ('scatter', 'VBN')), 3),\n",
       " ((('vara', 'NNP'), ('always', 'RB'), ('have', 'VBP')), 2),\n",
       " ((('so', 'RB'), ('too', 'RB'), ('do', 'VBZ')), 2),\n",
       " ((('vara', 'NNP'), ('loosely', 'RB'), ('indicate', 'VBZ')), 2),\n",
       " ((('be', 'VBP'), ('fairly', 'RB'), ('scatter', 'VBN')), 2),\n",
       " ((('but', 'CC'), ('there', 'RB'), ('seem', 'VBZ')), 2),\n",
       " ((('4-8', 'CD'), ('so', 'RB'), ('be', 'VBZ')), 2),\n",
       " ((('pretty', 'RB'), ('well', 'RB'), ('scatter', 'VBN')), 2),\n",
       " ((('do', 'VBP'), ('not', 'RB'), ('see', 'VB')), 2),\n",
       " ((('to', 'TO'), ('also', 'RB'), ('be', 'VB')), 2),\n",
       " ((('do', 'VBP'), ('not', 'RB'), ('have', 'VB')), 2),\n",
       " ((('fairly', 'RB'), ('evenly', 'RB'), ('distribute', 'VBN')), 2),\n",
       " ((('not', 'RB'), ('tightly', 'RB'), ('correlate', 'VBN')), 2),\n",
       " ((('not', 'RB'), ('always', 'RB'), ('be', 'VB')), 2),\n",
       " ((('an', 'DT'), ('even', 'RB'), ('spread', 'VBN')), 2),\n",
       " ((('do', 'VBP'), ('not', 'RB'), ('seem', 'VB')), 2),\n",
       " ((('pattern', 'NN'), ('here', 'RB'), ('suggesting', 'VBG')), 2),\n",
       " ((('to', 'TO'), ('equally', 'RB'), ('distribute', 'VBN')), 2),\n",
       " ((('do', 'VBP'), ('not', 'RB'), ('feel', 'VB')), 2),\n",
       " ((('data', 'NNS'), ('also', 'RB'), ('show', 'VBZ')), 2),\n",
       " ((('vara', 'NNP'), ('usually', 'RB'), ('lead', 'VBZ')), 2),\n",
       " ((('be', 'VBP'), ('well', 'RB'), ('correlate', 'VBN')), 1),\n",
       " ((('numerically', 'RB'), ('so', 'RB'), ('do', 'VBZ')), 1),\n",
       " ((('move', 'VB'), ('diagonally', 'RB'), ('upwards', 'VBZ')), 1),\n",
       " ((('do', 'VBZ'), ('too', 'RB'), ('showing', 'VBG')), 1),\n",
       " ((('value', 'NN'), ('so', 'RB'), ('be', 'VBZ')), 1),\n",
       " ((('you', 'PRP'), ('also', 'RB'), ('get', 'VBP')), 1),\n",
       " ((('quite', 'RB'), ('widely', 'RB'), ('distribute', 'VBN')), 1),\n",
       " ((('dot', 'NNS'), ('almost', 'RB'), ('form', 'VBP')), 1),\n",
       " ((('vara', 'NNP'), ('typically', 'RB'), ('indicate', 'VBZ')), 1),\n",
       " ((('be', 'VB'), ('evenly', 'RB'), ('distribute', 'VBN')), 1),\n",
       " ((('to', 'TO'), ('again', 'RB'), ('be', 'VB')), 1),\n",
       " ((('be', 'VBP'), ('most', 'RBS'), ('define', 'VBN')), 1),\n",
       " ((('value', 'NN'), ('so', 'RB'), ('do', 'VBZ')), 1),\n",
       " ((('fairly', 'RB'), ('even', 'RB'), ('spread', 'VBN')), 1),\n",
       " ((('value', 'NNS'), ('generally', 'RB'), ('increase', 'VBZ')), 1),\n",
       " ((('varb', 'NNP'), ('generally', 'RB'), ('do', 'VBZ')), 1),\n",
       " ((('generally', 'RB'), ('also', 'RB'), ('correlate', 'VBZ')), 1),\n",
       " ((('be', 'VBP'), ('mainly', 'RB'), ('congest', 'VBN')), 1),\n",
       " ((('be', 'VBZ'), ('randomly', 'RB'), ('distribute', 'VBN')), 1),\n",
       " ((('higher', 'RBR'), ('so', 'RB'), ('do', 'VB')), 1),\n",
       " ((('be', 'VBP'), ('not', 'RB'), ('close', 'VB')), 1),\n",
       " ((('but', 'CC'), ('very', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('be', 'VBP'), ('evenly', 'RB'), ('distribute', 'VBN')), 1),\n",
       " ((('increase', 'VBN'), ('so', 'RB'), ('be', 'VBZ')), 1),\n",
       " ((('varb', 'NNP'), ('again', 'RB'), ('appear', 'VBP')), 1),\n",
       " ((('be', 'VB'), ('more', 'RBR'), ('scatter', 'VBN')), 1),\n",
       " ((('but', 'CC'), ('also', 'RB'), ('seem', 'VBP')), 1),\n",
       " ((('they', 'PRP'), ('also', 'RB'), ('tend', 'VBP')), 1),\n",
       " ((('do', 'VBP'), ('not', 'RB'), ('conform', 'VB')), 1),\n",
       " ((('up', 'RP'), ('so', 'RB'), ('do', 'VBZ')), 1),\n",
       " ((('chart', 'NN'), ('here', 'RB'), ('gather', 'VBZ')), 1),\n",
       " ((('not', 'RB'), ('closely', 'RB'), ('link', 'VBN')), 1),\n",
       " ((('dot', 'NNS'), ('there', 'RB'), ('seem', 'VBZ')), 1),\n",
       " ((('vara', 'NNP'), ('also', 'RB'), ('increase', 'VBZ')), 1),\n",
       " ((('be', 'VBZ'), ('linearly', 'RB'), ('relate', 'VBN')), 1),\n",
       " ((('variable', 'NN'), ('also', 'RB'), ('appear', 'VBZ')), 1),\n",
       " ((('seem', 'VBP'), ('randomly', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('variable', 'NNS'), ('not', 'RB'), ('being', 'VBG')), 1),\n",
       " ((('linear', 'JJ'), ('yet', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('be', 'VBP'), ('very', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('only', 'RB'), ('slightly', 'RB'), ('correlate', 'VBD')), 1),\n",
       " ((('a', 'DT'), ('generally', 'RB'), ('centralize', 'VBN')), 1),\n",
       " ((('dot', 'NNS'), ('mostly', 'RB'), ('situate', 'VBN')), 1),\n",
       " ((('data', 'NNS'), ('here', 'RB'), ('look', 'VBZ')), 1),\n",
       " ((('mostly', 'RB'), ('not', 'RB'), ('surpassing', 'VBG')), 1),\n",
       " ((('to', 'TO'), ('not', 'RB'), ('be', 'VB')), 1),\n",
       " ((('become', 'VB'), ('less', 'RBR'), ('scatter', 'VBN')), 1),\n",
       " ((('varb', 'NNP'), ('generally', 'RB'), ('increase', 'VBZ')), 1),\n",
       " ((('scatter', 'VBN'), ('there', 'RB'), ('seem', 'VBZ')), 1),\n",
       " ((('gather', 'VBN'), ('here', 'RB'), ('be', 'VBZ')), 1),\n",
       " ((('more', 'RBR'), ('broadly', 'RB'), ('distribute', 'VBN')), 1),\n",
       " ((('suggesting', 'VBG'), ('there', 'RB'), ('isnt', 'VB')), 1),\n",
       " ((('quite', 'RB'), ('closely', 'RB'), ('connect', 'VBN')), 1),\n",
       " ((('be', 'VBZ'), ('more', 'RBR'), ('scatter', 'VBN')), 1),\n",
       " ((('pattern', 'NN'), ('mostly', 'RB'), ('look', 'VBZ')), 1),\n",
       " ((('range', 'NN'), ('more', 'RBR'), ('match', 'VBN')), 1),\n",
       " ((('look', 'VBP'), ('evenly', 'RB'), ('spread', 'VBN')), 1),\n",
       " ((('completely', 'RB'), ('randomly', 'RB'), ('place', 'VBN')), 1),\n",
       " ((('discern', 'VBN'), ('evenly', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('varb', 'NNP'), ('here', 'RB'), ('be', 'VBP')), 1),\n",
       " ((('by', 'IN'), ('generally', 'RB'), ('do', 'VBZ')), 1),\n",
       " ((('be', 'VBZ'), ('so', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('seem', 'VBP'), ('very', 'RB'), ('spead', 'VBN')), 1),\n",
       " ((('still', 'RB'), ('quite', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('do', 'VBZ'), ('not', 'RB'), ('look', 'VB')), 1),\n",
       " ((('would', 'MD'), ('probably', 'RB'), ('be', 'VB')), 1),\n",
       " ((('but', 'CC'), ('there', 'RB'), ('appear', 'VBZ')), 1),\n",
       " ((('quite', 'RB'), ('heavily', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('varb', 'NNP'), ('slightly', 'RB'), ('increase', 'VBZ')), 1),\n",
       " ((('and', 'CC'), ('therefore', 'RB'), ('do', 'VBP')), 1),\n",
       " ((('loosely', 'RB'), ('negatively', 'RB'), ('correlate', 'VBN')), 1),\n",
       " ((('increase', 'NNS'), ('then', 'RB'), ('decrease', 'VBZ')), 1),\n",
       " ((('seem', 'VBP'), ('very', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('more', 'RBR'), ('widely', 'RB'), ('space', 'VBN')), 1),\n",
       " ((('result', 'NNS'), ('there', 'RB'), ('isn', 'VBP')), 1),\n",
       " ((('relatively', 'RB'), ('evenly', 'RB'), ('distribute', 'VBN')), 1),\n",
       " ((('be', 'VBZ'), ('widely', 'RB'), ('distribute', 'VBN')), 1),\n",
       " ((('be', 'VB'), ('evenly', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('variable', 'NNS'), ('here', 'RB'), ('be', 'VBP')), 1),\n",
       " ((('a', 'DT'), ('fairly', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('relative', 'JJ'), ('even', 'RB'), ('scattering', 'VBG')), 1),\n",
       " ((('be', 'VBZ'), ('too', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('seem', 'VBZ'), ('very', 'RB'), ('vary', 'VBN')), 1),\n",
       " ((('have', 'VBZ'), ('very', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('however', 'RB'), ('there', 'RB'), ('do', 'VBZ')), 1),\n",
       " ((('a', 'DT'), ('very', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('but', 'CC'), ('generally', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('be', 'VBP'), ('closely', 'RB'), ('associate', 'VBN')), 1),\n",
       " ((('there', 'RB'), ('only', 'RB'), ('appear', 'VBZ')), 1),\n",
       " ((('the', 'DT'), ('brightly', 'RB'), ('light', 'VBN')), 1),\n",
       " ((('varb', 'NNP'), ('roughly', 'RB'), ('increase', 'VB')), 1),\n",
       " ((('can', 'MD'), ('not', 'RB'), ('see', 'VB')), 1),\n",
       " ((('but', 'CC'), ('then', 'RB'), ('be', 'VBZ')), 1),\n",
       " ((('be', 'VBZ'), ('quite', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('and', 'CC'), ('consistently', 'RB'), ('rise', 'VBZ')), 1),\n",
       " ((('this', 'DT'), ('again', 'RB'), ('be', 'VBZ')), 1),\n",
       " ((('that', 'DT'), ('almost', 'RB'), ('make', 'VBZ')), 1),\n",
       " ((('relationship', 'NN'), ('extremely', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('data', 'NNS'), ('here', 'RB'), ('seem', 'VBZ')), 1),\n",
       " ((('be', 'VBZ'), ('only', 'RB'), ('indicate', 'VBN')), 1),\n",
       " ((('be', 'VBZ'), ('extremely', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('information', 'NN'), ('here', 'RB'), ('be', 'VBZ')), 1),\n",
       " ((('be', 'VBZ'), ('widely', 'RB'), ('spread', 'VBN')), 1),\n",
       " ((('be', 'VBP'), ('generally', 'RB'), ('group', 'VBN')), 1),\n",
       " ((('be', 'VB'), ('equally', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('pretty', 'RB'), ('even', 'RB'), ('spread', 'VBN')), 1),\n",
       " ((('varb', 'NNP'), ('there', 'RB'), ('appear', 'VBZ')), 1),\n",
       " ((('fairly', 'RB'), ('evenly', 'RB'), ('spread', 'VBN')), 1),\n",
       " ((('dot', 'NNS'), ('evenly', 'RB'), ('place', 'VBN')), 1),\n",
       " ((('and', 'CC'), ('more', 'RBR'), ('focus', 'VBN')), 1),\n",
       " ((('do', 'VBD'), ('not', 'RB'), ('seem', 'VB')), 1),\n",
       " ((('seem', 'VBZ'), ('very', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('be', 'VBP'), ('rather', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('it', 'PRP'), ('almost', 'RB'), ('appear', 'VBZ')), 1),\n",
       " ((('do', 'VBZ'), ('somewhat', 'RB'), ('correlate', 'VB')), 1),\n",
       " ((('forming', 'VBG'), ('there', 'RB'), ('seem', 'VBZ')), 1),\n",
       " ((('pretty', 'RB'), ('well', 'RB'), ('distribute', 'VBN')), 1),\n",
       " ((('and', 'CC'), ('not', 'RB'), ('showing', 'VBG')), 1),\n",
       " ((('but', 'CC'), ('fairly', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('be', 'VB'), ('possibly', 'RB'), ('approximate', 'VBN')), 1),\n",
       " ((('data', 'NNS'), ('here', 'RB'), ('have', 'VBZ')), 1),\n",
       " ((('be', 'VBP'), ('somewhat', 'RB'), ('scatter', 'VBN')), 1),\n",
       " ((('very', 'RB'), ('easily', 'RB'), ('be', 'VB')), 1),\n",
       " ((('value', 'NN'), ('usually', 'RB'), ('mean', 'VBZ')), 1),\n",
       " ((('high', 'JJ'), ('then', 'RB'), ('drop', 'VB')), 1),\n",
       " ((('varb', 'NNP'), ('steadily', 'RB'), ('decreasing', 'VBG')), 1),\n",
       " ((('slope', 'NNS'), ('downward', 'RB'), ('look', 'VBZ')), 1),\n",
       " ((('vara', 'NNP'), ('generally', 'RB'), ('indicate', 'VBZ')), 1),\n",
       " ((('but', 'CC'), ('still', 'RB'), ('show', 'VBP')), 1),\n",
       " ((('varb', 'NNP'), ('clearly', 'RB'), ('decrease', 'VBZ')), 1),\n",
       " ((('be', 'VBP'), ('positively', 'RB'), ('correlate', 'VBN')), 1),\n",
       " ((('decrease', 'VBZ'), ('so', 'RB'), ('do', 'VBZ')), 1),\n",
       " ((('there', 'RB'), ('again', 'RB'), ('seem', 'VBZ')), 1)]"
      ]
     },
     "execution_count": 1000,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams = TrigramCollocationFinder.from_documents(data['lemmatized'].tolist())\n",
    "#bigrams.apply_ngram_filter(lambda w1,w2: not ((w2[0] in mcn)))\n",
    "trigrams.apply_ngram_filter(adverb_trigram_filter)\n",
    "#finder.apply_ngram_filter(lambda w1, w2: not ((w2[0] == \"relationship\") or (w2[0] == \"correlation\")))\n",
    "#bigrams.apply_freq_filter(2)\n",
    "\n",
    "#Convert them to a list so we can sort them by frequency\n",
    "adverb_trigram_list = list(trigrams.ngram_fd.items())\n",
    "adverb_trigram_list.sort(key=lambda item: item[-1], reverse=True)\n",
    "#for a,b in bigram_list:\n",
    "#    print(a[0][0],a[1][0],b)\n",
    "adverb_trigram_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging codes with answers\n",
    "\n",
    "From here, the analysis requires four files that map adjectives, nouns, verbs and adverbs to categories. These files should be CSV files with two columns: the first column contain the word that is being categorised, while the second column contains the category that the words belong to.\n",
    "\n",
    "Default names for the files are *adjective-category, noun-category, adverb-category and verb-category*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_cat = {\"not\": \"NEGATE\", \"no\": \"NEGATE\"}\n",
    "other_adj = {\"up\": \"DIRECTION\", \"down\": \"DIRECTION\", \n",
    "             \"above\": \"POSITION\", \"under\": \"POSITION\"} #, \"between\": \"POSITION\"}\n",
    "other_noun = {'vara': 'INFERENCES', 'varb': 'INFERENCES' }\n",
    "special = ['NEGATE']\n",
    "concepts = ['RELATION','BEHAVIOUR','SPACE','INFERENCES','GRAPHIC','OTHER']\n",
    "traits = ['MAGNITUDE','DIRECTION','POSITION','DISCERNIBILITY','REGULARITY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_cat = {}\n",
    "with open('lex-adjective.csv',encoding='utf-8') as f:\n",
    "    next(f)  # Skip the header\n",
    "    reader = csv.reader(f, delimiter=';', skipinitialspace=True)\n",
    "    tlist = []\n",
    "    for row in reader:\n",
    "        tlist.append(tuple([row[0], row[1]])) #append col1 and col 2 to myTuples\n",
    "    adj_cat = dict(tlist)\n",
    "    adj_list = tlist\n",
    "adj_cat.update(other_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_cat = {}\n",
    "with open('lex-noun.csv',encoding='utf-8') as f:\n",
    "    next(f)  # Skip the header\n",
    "    reader = csv.reader(f, delimiter=';', skipinitialspace=True)\n",
    "    tlist = []\n",
    "    for row in reader:\n",
    "        tlist.append(tuple([row[0], row[1]])) #append col1 and col 2 to myTuples\n",
    "    noun_cat = dict(tlist)\n",
    "    noun_list = tlist\n",
    "noun_cat.update(other_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_cat = {}\n",
    "with open('lex-adverb.csv',encoding='utf-8') as f:\n",
    "    next(f)  # Skip the header\n",
    "    reader = csv.reader(f, delimiter=';', skipinitialspace=True)\n",
    "    tlist = []\n",
    "    for row in reader:\n",
    "        tlist.append(tuple([row[0], row[1]])) #append col1 and col 2 to myTuples\n",
    "    adv_cat = dict(tlist)\n",
    "    adv_list = tlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_cat = {}\n",
    "with open('lex-verb.csv',encoding='utf-8') as f:\n",
    "    next(f)  # Skip the header\n",
    "    reader = csv.reader(f, delimiter=';', skipinitialspace=True)\n",
    "    tlist = []\n",
    "    for row in reader:\n",
    "        tlist.append(tuple([row[0], row[1]])) #append col1 and col 2 to myTuples\n",
    "    verb_cat = dict(tlist)\n",
    "    verb_list = tlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'cat_dict' (dict)\n"
     ]
    }
   ],
   "source": [
    "cat_list = adj_list+noun_list+adv_list+verb_list\n",
    "cat_dict = dict(cat_list)\n",
    "cat_dict.update(other_noun)\n",
    "cat_dict.update(other_adj)\n",
    "%store cat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_from_lists(sentence,*args):\n",
    "    new_sentence = []\n",
    "    for word,pos in sentence:\n",
    "        for lst in args:\n",
    "            if word in lst and lst[word] not in new_sentence:\n",
    "                if (lst[word] != \"NONE\"):\n",
    "                    new_sentence.append(lst[word])\n",
    "#        if (word in list_of_adjs):\n",
    "#            new_sentence.append((list_of_adjs[word],pos))\n",
    "#        elif (word in list_of_nouns):\n",
    "#            new_sentence.append((list_of_nouns[word],pos))\n",
    "#        new_sentence.append((word,pos))\n",
    "    if len(new_sentence) == 0:\n",
    "        return np.nan\n",
    "    return new_sentence\n",
    "        \n",
    "data['lemma_cat_tagged'] = data['lemmatized'].apply(tag_from_lists,args=(cat_dict,other_cat))    \n",
    "#data['lemma_cat_tagged'] = data['lemmatized'].apply(tag_from_lists,args=(adj_cat,noun_cat,adv_cat,other_cat,verb_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After collecting the tags from the categorised lists of adjectives, nouns, adverbs, verbs and others, we manually check the remaining utterances (which with luck may not be many) and retrospectively add words to the *other_cat* list above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration (in seconds)</th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tagged</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>stop_tags</th>\n",
       "      <th>openie</th>\n",
       "      <th>openie_replaced</th>\n",
       "      <th>word_count</th>\n",
       "      <th>lemma_cat_tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1043</td>\n",
       "      <td>R_12bP3GmnPe4by1t</td>\n",
       "      <td>C8P</td>\n",
       "      <td>I see a plane or rocket</td>\n",
       "      <td>[I, see, a, plane, or, rocket]</td>\n",
       "      <td>[(i, LS), (see, VB), (a, DT), (plane, NN), (or...</td>\n",
       "      <td>[(i, LS), (see, VB), (a, DT), (plane, NN), (or...</td>\n",
       "      <td>plane rocket</td>\n",
       "      <td>(see, I, plane)</td>\n",
       "      <td>(see, I, plane)</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>1043</td>\n",
       "      <td>R_12bP3GmnPe4by1t</td>\n",
       "      <td>C6P</td>\n",
       "      <td>Varied. Looks like a map of the stars</td>\n",
       "      <td>[Varied, Looks, like, a, map, of, the, stars]</td>\n",
       "      <td>[(varied, JJ), (looks, NNS), (like, IN), (a, D...</td>\n",
       "      <td>[(varied, JJ), (look, NNS), (like, IN), (a, DT...</td>\n",
       "      <td>varied look map star</td>\n",
       "      <td>(, , )</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>347</td>\n",
       "      <td>R_1i2Tczn8HRGlWzj</td>\n",
       "      <td>C6P</td>\n",
       "      <td>Spearhead</td>\n",
       "      <td>[Spearhead]</td>\n",
       "      <td>[(spearhead, NN)]</td>\n",
       "      <td>[(spearhead, NN)]</td>\n",
       "      <td>spearhead</td>\n",
       "      <td>(, , )</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>1043</td>\n",
       "      <td>R_12bP3GmnPe4by1t</td>\n",
       "      <td>C4P</td>\n",
       "      <td>I see a marching horse</td>\n",
       "      <td>[I, see, a, marching, horse]</td>\n",
       "      <td>[(i, LS), (see, VB), (a, DT), (marching, VBG),...</td>\n",
       "      <td>[(i, LS), (see, VB), (a, DT), (marching, VBG),...</td>\n",
       "      <td>horse</td>\n",
       "      <td>(see, I, horse)</td>\n",
       "      <td>(see, I, horse)</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>460</td>\n",
       "      <td>R_yz2TNy403IoUadj</td>\n",
       "      <td>C4P</td>\n",
       "      <td>Wealth-distribution is at a full-trot.</td>\n",
       "      <td>[Wealth-distribution, is, at, a, full-trot]</td>\n",
       "      <td>[(wealth-distribution, NN), (is, VBZ), (at, IN...</td>\n",
       "      <td>[(wealth-distribution, NN), (be, VBZ), (at, IN...</td>\n",
       "      <td>wealth-distribution full-trot</td>\n",
       "      <td>(is at, Wealth-distribution, full-trot)</td>\n",
       "      <td>(is at, Wealth-distribution, full-trot)</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>1404</td>\n",
       "      <td>R_1nWbapPPi4ZuWd7</td>\n",
       "      <td>C2P</td>\n",
       "      <td>Don't know</td>\n",
       "      <td>[Don, t, know]</td>\n",
       "      <td>[(don, VB), (t, NN), (know, VBP)]</td>\n",
       "      <td>[(don, VB), (t, NN), (know, VBP)]</td>\n",
       "      <td>t</td>\n",
       "      <td>(, , )</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>130</td>\n",
       "      <td>R_C84psnIjacPg00N</td>\n",
       "      <td>C4N</td>\n",
       "      <td>none</td>\n",
       "      <td>[none]</td>\n",
       "      <td>[(none, NN)]</td>\n",
       "      <td>[(none, NN)]</td>\n",
       "      <td>none</td>\n",
       "      <td>(, , )</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>460</td>\n",
       "      <td>R_yz2TNy403IoUadj</td>\n",
       "      <td>C6N</td>\n",
       "      <td>Grocery shopping while hungry.</td>\n",
       "      <td>[Grocery, shopping, while, hungry]</td>\n",
       "      <td>[(grocery, NN), (shopping, NN), (while, IN), (...</td>\n",
       "      <td>[(grocery, NN), (shopping, NN), (while, IN), (...</td>\n",
       "      <td>grocery shopping hungry</td>\n",
       "      <td>(, , )</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>776</td>\n",
       "      <td>R_3LdT9l1ucZpS5jr</td>\n",
       "      <td>C8N</td>\n",
       "      <td>Nothing between 0 and 6 for both axis</td>\n",
       "      <td>[Nothing, between, 0, and, 6, for, both, axis]</td>\n",
       "      <td>[(nothing, NN), (between, IN), (0, CD), (and, ...</td>\n",
       "      <td>[(nothing, NN), (between, IN), (0, CD), (and, ...</td>\n",
       "      <td>nothing axis</td>\n",
       "      <td>(, , )</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Duration (in seconds)         ResponseId Question  \\\n",
       "46                     1043  R_12bP3GmnPe4by1t      C8P   \n",
       "206                    1043  R_12bP3GmnPe4by1t      C6P   \n",
       "267                     347  R_1i2Tczn8HRGlWzj      C6P   \n",
       "366                    1043  R_12bP3GmnPe4by1t      C4P   \n",
       "436                     460  R_yz2TNy403IoUadj      C4P   \n",
       "586                    1404  R_1nWbapPPi4ZuWd7      C2P   \n",
       "974                     130  R_C84psnIjacPg00N      C4N   \n",
       "1236                    460  R_yz2TNy403IoUadj      C6N   \n",
       "1403                    776  R_3LdT9l1ucZpS5jr      C8N   \n",
       "\n",
       "                                        Answer  \\\n",
       "46                     I see a plane or rocket   \n",
       "206     Varied. Looks like a map of the stars    \n",
       "267                                 Spearhead    \n",
       "366                     I see a marching horse   \n",
       "436   Wealth-distribution is at a full-trot.     \n",
       "586                                 Don't know   \n",
       "974                                       none   \n",
       "1236            Grocery shopping while hungry.   \n",
       "1403     Nothing between 0 and 6 for both axis   \n",
       "\n",
       "                                           tokenized  \\\n",
       "46                    [I, see, a, plane, or, rocket]   \n",
       "206    [Varied, Looks, like, a, map, of, the, stars]   \n",
       "267                                      [Spearhead]   \n",
       "366                     [I, see, a, marching, horse]   \n",
       "436      [Wealth-distribution, is, at, a, full-trot]   \n",
       "586                                   [Don, t, know]   \n",
       "974                                           [none]   \n",
       "1236              [Grocery, shopping, while, hungry]   \n",
       "1403  [Nothing, between, 0, and, 6, for, both, axis]   \n",
       "\n",
       "                                                 tagged  \\\n",
       "46    [(i, LS), (see, VB), (a, DT), (plane, NN), (or...   \n",
       "206   [(varied, JJ), (looks, NNS), (like, IN), (a, D...   \n",
       "267                                   [(spearhead, NN)]   \n",
       "366   [(i, LS), (see, VB), (a, DT), (marching, VBG),...   \n",
       "436   [(wealth-distribution, NN), (is, VBZ), (at, IN...   \n",
       "586                   [(don, VB), (t, NN), (know, VBP)]   \n",
       "974                                        [(none, NN)]   \n",
       "1236  [(grocery, NN), (shopping, NN), (while, IN), (...   \n",
       "1403  [(nothing, NN), (between, IN), (0, CD), (and, ...   \n",
       "\n",
       "                                             lemmatized  \\\n",
       "46    [(i, LS), (see, VB), (a, DT), (plane, NN), (or...   \n",
       "206   [(varied, JJ), (look, NNS), (like, IN), (a, DT...   \n",
       "267                                   [(spearhead, NN)]   \n",
       "366   [(i, LS), (see, VB), (a, DT), (marching, VBG),...   \n",
       "436   [(wealth-distribution, NN), (be, VBZ), (at, IN...   \n",
       "586                   [(don, VB), (t, NN), (know, VBP)]   \n",
       "974                                        [(none, NN)]   \n",
       "1236  [(grocery, NN), (shopping, NN), (while, IN), (...   \n",
       "1403  [(nothing, NN), (between, IN), (0, CD), (and, ...   \n",
       "\n",
       "                          stop_tags                                   openie  \\\n",
       "46                     plane rocket                          (see, I, plane)   \n",
       "206            varied look map star                                   (, , )   \n",
       "267                       spearhead                                   (, , )   \n",
       "366                           horse                          (see, I, horse)   \n",
       "436   wealth-distribution full-trot  (is at, Wealth-distribution, full-trot)   \n",
       "586                               t                                   (, , )   \n",
       "974                            none                                   (, , )   \n",
       "1236        grocery shopping hungry                                   (, , )   \n",
       "1403                   nothing axis                                   (, , )   \n",
       "\n",
       "                              openie_replaced  word_count lemma_cat_tagged  \n",
       "46                            (see, I, plane)           6              NaN  \n",
       "206                                       NaN           8              NaN  \n",
       "267                                       NaN           1              NaN  \n",
       "366                           (see, I, horse)           5              NaN  \n",
       "436   (is at, Wealth-distribution, full-trot)           5              NaN  \n",
       "586                                       NaN           3              NaN  \n",
       "974                                       NaN           1              NaN  \n",
       "1236                                      NaN           4              NaN  \n",
       "1403                                      NaN           8              NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['lemma_cat_tagged'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now save what we got until here so we can visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(\"WECdf-categorised.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can also re-load any previously categorised data to continue the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"WECdf-categorised.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of tagged utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = data.copy()\n",
    "#df['lemma_cat_tagged'] = df['lemma_cat_tagged'].apply(sorted).apply(tuple)\n",
    "#df['lemma_cat_tagged'] = df['lemma_cat_tagged'].apply(lambda x: x if (len(x) == 2 and set(x).issuperset(('BEHAVIOUR','INFERENCES'))) else None)\n",
    "#with pd.option_context('display.max_rows', None, 'display.max_colwidth', -1):\n",
    "#    display(df.dropna(subset=['lemma_cat_tagged']).Answer)\n",
    "#to_chart = df.groupby(['lemma_cat_tagged']).apply(len).sort_values(ascending=False)[:10]#.where(lambda x: x == 1).dropna()he\n",
    "#%store to_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cdata[cdata['traits'].apply(lambda x: True if len(x) == 0 else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixes empty lemma cat taggeds\n",
    "d = data['lemma_cat_tagged']\n",
    "d.loc[d.isnull()] = d.loc[d.isnull()].apply(lambda x: [])\n",
    "data['lemma_cat_tagged'] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['contains'] = data['lemma_cat_tagged'].dropna().apply(tuple).apply(lambda x: True if ('POSITION' in x) else False)\n",
    "#data[data['contains'] == True]['Answer']\n",
    "#.to_csv('PositionAnswers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['independent', 'diffuse', 'clear', 'real', 'unrelated', 'present', 'discernible', 'readable', 'distinct', 'definite', 'definitive', 'unconnected', 'vague', 'identifiable', 'general', 'noticeable', 'possible', 'obvious', 'distinctive', 'particular']\n",
      "21    the trend follows a clear upward rise                                                                                                                                                                                                  \n",
      "26    The relationship between the variables seems to be that as VarA goes higher numerically, so does VarB. There is a seemingly distinct pattern where the data seems to move diagonally upwards, with a clear path to 10 on each variable.\n",
      "35    As VarA increases, VarB does too, showing a fairly clear relationship between the two.                                                                                                                                                 \n",
      "55    Both variables increase at an obvious rate                                                                                                                                                                                             \n",
      "56    A positive correlation is present, points are quite widely distributed.                                                                                                                                                                \n",
      "Name: Answer, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#adjs = [word for word in  if adj_cat[word] == 'DIRECTION']\n",
    "def filter_w(sentence):\n",
    "    for word in sentence:\n",
    "        if (word[0] in adj_cat):\n",
    "            if adj_cat[word[0]] == \"DISCERNIBILITY\":\n",
    "                return word[0]\n",
    "direction_adjs = data['lemmatized'].apply(filter_w).dropna().values\n",
    "print(list(set(direction_adjs)))\n",
    "#data['lemmatized'].apply(lambda x: x)\n",
    "def pt(x):\n",
    "    for word in x:\n",
    "        if (word[0] in direction_adjs):            \n",
    "            return True\n",
    "    return False\n",
    "filtered = data.loc[data.lemmatized.apply(pt)]\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "print(filtered.loc[data.lemmatized.apply(pt)]['Answer'][:5])\n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_c(sentence):\n",
    "    for word in sentence:\n",
    "        if (word[0] in noun_cat):\n",
    "            if noun_cat[word[0]] == \"GRAPHIC\":\n",
    "                return word[0]\n",
    "behaviour_nouns = data['lemmatized'].apply(filter_c).dropna().values\n",
    "def cf(x):\n",
    "    for word in x:\n",
    "        if (word[0] in behaviour_nouns):            \n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_category(sentence,list_cat,adj_filter,func):\n",
    "    lst= []\n",
    "    c = FreqDist()\n",
    "    for sent in sentence['lemmatized']:\n",
    "        #print(word)\n",
    "        for word in sent:\n",
    "            if (word[0] in list_cat): #and (word[1].startswith(func)):\n",
    "                if list_cat[word[0]] == adj_filter:\n",
    "                    c.update([word[0]])\n",
    "                    #lst.append(word[0])\n",
    "    return sorted(list(c.items()),key=lambda x: -x[1])\n",
    "\n",
    "def filter_by_type(sentence,func):\n",
    "    lst= []\n",
    "    c = FreqDist()\n",
    "    for sent in sentence['lemmatized']:\n",
    "        #print(word)\n",
    "        for word in sent:\n",
    "            if (word[1].startswith(func)):\n",
    "                c.update([word[0]])\n",
    "                    #lst.append(word[0])\n",
    "    return sorted(list(c.items()),key=lambda x: -x[1])[:10]\n",
    "#list_words = data.groupby(\"Question\").apply(lambda x: filter_by_category(x,cat_dict,'MAGNITUDE','JJ')).dropna().reset_index().rename(columns={0: \"words\"})#.apply(set).apply(list)\n",
    "list_words = data.groupby(\"Question\").apply(lambda x: filter_by_type(x,'JJ')).dropna().reset_index().rename(columns={0: \"words\"})\n",
    "list_words['Question'] = list_words['Question'].apply(lambda x: floatQ[x])\n",
    "list_words = list_words.sort_values(by=['Question']).reset_index(drop=True)\n",
    "#pd.set_option('display.max_colwidth', -1)\n",
    "#pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Question</td><td>-0.8                                                                                                                                                     </td><td>-0.6                                                                                                                                              </td><td>-0.4                                                                                                                                                 </td><td>-0.2                                                                                                                                               </td><td>0.0                                                                                                                                        </td><td>0.2                                                                                                                                                </td><td>0.4                                                                                                                                                   </td><td>0.6                                                                                                                                               </td><td>0.8                                                                                                                                                  </td></tr>\n",
       "<tr><td>words   </td><td>[('high', 53), ('low', 46), ('negative', 37), ('strong', 15), ('clear', 11), ('linear', 9), ('diagonal', 8), ('inverse', 5), ('downward', 5), ('few', 4)]</td><td>[('high', 45), ('negative', 36), ('low', 34), ('weak', 10), ('slight', 7), ('general', 5), ('more', 5), ('strong', 5), ('loose', 4), ('other', 4)]</td><td>[('negative', 18), ('random', 18), ('high', 17), ('low', 16), ('slight', 13), ('clear', 11), ('weak', 6), ('obvious', 6), ('little', 5), ('wide', 4)]</td><td>[('random', 19), ('high', 16), ('low', 15), ('little', 12), ('weak', 9), ('clear', 9), ('positive', 6), ('other', 6), ('negative', 6), ('real', 5)]</td><td>[('random', 23), ('clear', 12), ('high', 9), ('low', 8), ('little', 7), ('much', 5), ('few', 5), ('obvious', 4), ('other', 4), ('more', 3)]</td><td>[('random', 16), ('positive', 14), ('high', 12), ('clear', 12), ('slight', 10), ('low', 9), ('few', 8), ('weak', 7), ('direct', 5), ('similar', 5)]</td><td>[('high', 32), ('positive', 26), ('low', 16), ('random', 12), ('weak', 10), ('slight', 10), ('linear', 8), ('clear', 7), ('general', 6), ('loose', 5)]</td><td>[('high', 39), ('positive', 31), ('low', 15), ('strong', 11), ('general', 8), ('slight', 8), ('linear', 6), ('loose', 6), ('few', 6), ('weak', 5)]</td><td>[('positive', 35), ('high', 31), ('strong', 20), ('linear', 13), ('low', 10), ('clear', 7), ('same', 5), ('few', 5), ('similar', 5), ('diagonal', 5)]</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#list_words['words'] = list_words['words'].apply(lambda x: len(x))\n",
    "lt = list_words.transpose() #.reindex([\"Question\",-0.8,-0.6,-0.4,-0.2,0,0.2,0.4,0.6,0.8],axis=1)\n",
    "#lt = lt.reindex(sorted(lt.columns,key=float), axis=1)\n",
    "display(HTML(tabulate.tabulate(lt, tablefmt='html')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data wrangling for analysing categories\n",
    "\n",
    "The next few blocks process data so that we can compare the results of both experiments.\n",
    "We read 5 csv files that contain a mapping of adjectives to scales. As each trait contains different types of adjectives (e.g. \"amount\" and \"strength\" adjectives), they will be obviously very subjective. We are also excluding some of the adjectives that do not really match with the statements used in the second experiment -- for magnitude, for example, we only kept strong, moderate and weak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['independent', 'vague', 'readable', 'unrelated', 'definite', 'diffuse', 'real', 'distinctive', 'particular', 'distinct', 'general', 'noticeable', 'clear', 'possible', 'unconnected', 'discernible', 'identifiable', 'present', 'definitive', 'obvious']\n"
     ]
    }
   ],
   "source": [
    "def filter_series_by_category(sentence,list_cat,cat_filter,func):\n",
    "#    lst= []\n",
    "    for word in sentence:\n",
    "        if (word[0] in list_cat) and (word[1].startswith(func)):\n",
    "            if list_cat[word[0]] == cat_filter:\n",
    "                return word[0]\n",
    "\n",
    "    #return sorted(list(c.items()),key=lambda x: -x[1])\n",
    "\n",
    "list_of = list(set(data['lemmatized'].apply(lambda x: filter_series_by_category(x,cat_dict,'DISCERNIBILITY','JJ')).dropna().values))\n",
    "list_2 = list(set(data['lemmatized'].apply(lambda x: filter_series_by_category(x,cat_dict,'RELATION','NN')).dropna().values))\n",
    "print(list_of)\n",
    "def cf(x,list_cat,func):\n",
    "    for word in x:\n",
    "        if (word[0] in list_cat): #and (word[1].startswith(func)):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "filtered = data.loc[data.lemmatized.apply(lambda x: cf(x,list_of,'JJ'))].dropna(axis=1)[['ResponseId','Question','Answer','lemmatized','lemma_cat_tagged']]\n",
    "filtered2 = data.loc[data.lemmatized.apply(lambda x: cf(x,list_2,'NN'))].dropna(axis=1)[['ResponseId','Question','Answer','lemmatized','lemma_cat_tagged']]\n",
    "#print(filtered)\n",
    "filtered.lemmatized = filtered.lemmatized.apply(tuple)\n",
    "filtered2.lemmatized = filtered2.lemmatized.apply(tuple)\n",
    "filtered.lemma_cat_tagged = filtered.lemma_cat_tagged.apply(tuple)\n",
    "filtered2.lemma_cat_tagged = filtered2.lemma_cat_tagged.apply(tuple)\n",
    "merged = filtered.merge(filtered2,how='right')\n",
    "merged.lemmatized = merged.lemmatized.apply(list)\n",
    "merged.lemma_cat_tagged = merged.lemma_cat_tagged.apply(list)\n",
    "#pd.set_option('display.max_colwidth', -1)\n",
    "#print(merged[merged['Question'] == 'C0'].Answer)\n",
    "#display(filtered[['Answer']])\n",
    "#pd.reset_option('display.max_colwidth')\n",
    "#filtered['Answer']))\n",
    "#filtered[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clear',\n",
       " 'definitive',\n",
       " 'discernible',\n",
       " 'distinct',\n",
       " 'identifiable',\n",
       " 'independent',\n",
       " 'noticeable',\n",
       " 'obvious',\n",
       " 'particular',\n",
       " 'possible',\n",
       " 'real',\n",
       " 'vague'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tightly'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def match_ngram(sentence,list_cat,adj,noun):\n",
    "    bcf = BigramCollocationFinder.from_words(sentence)\n",
    "    bcf.apply_ngram_filter(bigram_filter)\n",
    "    bcf.apply_ngram_filter(lambda w1,w2: not ((list_cat[w2[0]] == noun if w2[0] in list_cat else True) and (list_cat[w1[0]] == adj if w1[0] in list_cat else True))   )\n",
    "    #display(bcf.ngram_fd.items())\n",
    "    if (len(bcf.ngram_fd.items()) > 0):\n",
    "        return True\n",
    "    #bcf.apply_ngram_filter(lambda w1,w2: not (adj_cat[w1[0]] == adj if w1[0] in list_cat else True))\n",
    "    tcf = TrigramCollocationFinder.from_words(sentence)    \n",
    "    tcf.apply_ngram_filter(trigram_filter)\n",
    "    tcf.apply_ngram_filter(lambda w1,w2,w3: not ((list_cat[w3[0]] == noun if w3[0] in list_cat else True)\n",
    "                                                 and((list_cat[w2[0]] == adj if w2[0] in list_cat else True)  or  (list_cat[w1[0]] == adj if w1[0] in list_cat else True))  ) )\n",
    "    if (len(tcf.ngram_fd.items()) > 0):\n",
    "        return True\n",
    "    \n",
    "    bcf = BigramCollocationFinder.from_words(sentence)\n",
    "    bcf.apply_ngram_filter(adverb_filter)\n",
    "    bcf.apply_ngram_filter(lambda w1,w2: not ((list_cat[w2[0]] == noun if w2[0] in list_cat else True) and (list_cat[w1[0]] == adj if w1[0] in list_cat else True))   )\n",
    "    if (len(bcf.ngram_fd.items()) > 0):\n",
    "        return True\n",
    "    \n",
    "    \n",
    "    return False\n",
    "#list_of = list(set(data['lemmatized'].apply(lambda x: filter_series_by_category(x,cat_dict,'MAGNITUDE','JJ')).dropna().values))\n",
    "#display(list_of)\n",
    "adj_match = 'DISCERNIBILITY'\n",
    "noun_match = 'RELATION'\n",
    "\n",
    "filtered = data.loc[data.lemmatized.apply(lambda x: match_ngram(x,cat_dict,adj_match,noun_match))].dropna(axis=1)[['ResponseId','Question','Answer','lemmatized','lemma_cat_tagged']]\n",
    "\n",
    "bcf = BigramCollocationFinder.from_documents(filtered['lemmatized'].to_list())\n",
    "bcf.apply_ngram_filter(bigram_filter)\n",
    "bcf.apply_ngram_filter(lambda w1,w2: not ((noun_cat[w2[0]] == noun_match if w2[0] in noun_cat else True) and (adj_cat[w1[0]] == adj_match if w1[0] in adj_cat else True))   )\n",
    "display(set([jj[0][0][0] for jj in bcf.ngram_fd.items()]))\n",
    "bcf = BigramCollocationFinder.from_documents(filtered['lemmatized'].to_list())\n",
    "bcf.apply_ngram_filter(adverb_filter)\n",
    "bcf.apply_ngram_filter(lambda w1,w2: not ((verb_cat[w2[0]] == noun_match if w2[0] in verb_cat else True) and (adv_cat[w1[0]] == adj_match if w1[0] in adv_cat else True))   )\n",
    "display(set([jj[0][0][0] for jj in bcf.ngram_fd.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A strong positive correlation; as one variable increases, so does the other.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>strong positive relationship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>weak positive correlation, VarA is roughly equal to VarB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>There is a linear relationship between VarA and VarB, that is to say that they are well correlated here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>strong positive correlation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Generally linked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>There is a fairly strong positive correlation between variables. As VarA increases so does VarB.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>There is a strong correlation between variables VarA and VarB being almost the same, though with some deviation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Strong correlation. As VarA increases VarB also increases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Appears to be a weak positive correlation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>A moderate positive relationship between VarA and VarB. As VarA increases, VarB also increases.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Strong positive correlation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>quite constant with middling lower statistics spreading from each extreme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>There is a very strong positive correlation between variables VarA and VarB.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>A fairly strong one-to-one correlation between values of VarA and VarB, with some randomness to it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>There is a relatively strong relationship between VarA and VarB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>There is a strong positive correlation between variables VarA and VarB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>strong positive correlation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>There is a strong correlation between the increase of VarB and the increase of VarA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Strong positive relationship.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>there is a strong positive correlation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>There's a pretty strong positive relationship between VarA and VarB; as VarA increases, VarB increases too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>a strong relationship between VarA and VarB. as VarA increases so does VarB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>The relationship between these variables develops distinctly towards 10 with little divergence from this rule.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Results are varied, there is a slight correlation in the higher number of VarA shows a higher number in VarB also.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Variables VarA and VarB have a weak-to-moderate positive correlation. As VarA increases, VarB increases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>There is a weak positive correlation between the variables.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>strong positive association with not many strong outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>likely independent, very slight positive correlation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>There is a moderate positive relationship between variables VarA and VarB. Higher values of VarA are associated with higher values of VarB, and a line of best fit can be matched with the data distribution.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>Appears to be a very weak negative correlation between variables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>Weak relationship between them</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>A moderate negative relationship between VarA and VarB. As VarA decreases, VarB also decreases.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>There is a moderately strong negative correlation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>There is a fairly strong relationship between VarA and VarB, as VarB decreases, VarA increases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>There is a lot of scatter but there seems to be a weak relation in that the bigger VarA is the smaller VarB will be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>the graph shows a rough negative correlation with some anomaly's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>There is a slight negative correlation. As VarA increases, VarB decreases. The points are far apart and not showing a strong correlation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>there is a slight negative correlation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>There appears to be a slight negative correlation between variables VarA and VarB in this chart.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>There's a moderate negative relationship - as VarA increases, VarB decreases by and large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>There is a strong correlation, the higher the VarB variable the lower the VarA variable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>There is a moderate negative correlation between \"VarA\" and \"VarB\"; As VarB increases, VarA decreases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>They have a fairly strong negative correlation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>strong negative relationship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>slight negative correlation, VarA is roughly (10-VarB)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>There is a fairly strong negative correlation between variables. As VarA increases VarB decreases.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>Appears a weak negative correlation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>strong negative correlation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>Strong correlation - an increase in VarA leads to a decrease in VarB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>A moderate negative relationship between VarA and VarB. As VarA decreases, VarB also decreases.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>Strong Negative correlation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>There is a strong negative correlation between variables VarA and VarB.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>stronger relationship at central values</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>strong negative correlation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>strong negative correlation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>There is a strong correlation between the decrease of VarB and the increase of VarA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>Medium-strong Negative relationship.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>The is a slight negative correlation between VarA and VarB. As VarA increases, VarB decreases. Conversely, as b increases, a decreases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>There's a relatively strong negative relationship - as VarA increases, VarB decreases</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                             Answer\n",
       "11    A strong positive correlation; as one variable increases, so does the other.                                                                                                                                 \n",
       "12    strong positive relationship                                                                                                                                                                                 \n",
       "13    weak positive correlation, VarA is roughly equal to VarB                                                                                                                                                     \n",
       "15    There is a linear relationship between VarA and VarB, that is to say that they are well correlated here                                                                                                      \n",
       "17    strong positive correlation                                                                                                                                                                                  \n",
       "19    Generally linked                                                                                                                                                                                             \n",
       "22    There is a fairly strong positive correlation between variables. As VarA increases so does VarB.                                                                                                             \n",
       "23    There is a strong correlation between variables VarA and VarB being almost the same, though with some deviation                                                                                              \n",
       "28    Strong correlation. As VarA increases VarB also increases                                                                                                                                                    \n",
       "57    Appears to be a weak positive correlation                                                                                                                                                                    \n",
       "77    A moderate positive relationship between VarA and VarB. As VarA increases, VarB also increases.                                                                                                              \n",
       "79    Strong positive correlation                                                                                                                                                                                  \n",
       "82    quite constant with middling lower statistics spreading from each extreme                                                                                                                                    \n",
       "84    There is a very strong positive correlation between variables VarA and VarB.                                                                                                                                 \n",
       "85    A fairly strong one-to-one correlation between values of VarA and VarB, with some randomness to it.                                                                                                          \n",
       "95    There is a relatively strong relationship between VarA and VarB                                                                                                                                              \n",
       "97    There is a strong positive correlation between variables VarA and VarB                                                                                                                                       \n",
       "110   strong positive correlation                                                                                                                                                                                  \n",
       "113   There is a strong correlation between the increase of VarB and the increase of VarA                                                                                                                          \n",
       "114   Strong positive relationship.                                                                                                                                                                                \n",
       "121   there is a strong positive correlation                                                                                                                                                                       \n",
       "145   There's a pretty strong positive relationship between VarA and VarB; as VarA increases, VarB increases too                                                                                                   \n",
       "146   a strong relationship between VarA and VarB. as VarA increases so does VarB                                                                                                                                  \n",
       "150   The relationship between these variables develops distinctly towards 10 with little divergence from this rule.                                                                                               \n",
       "163   Results are varied, there is a slight correlation in the higher number of VarA shows a higher number in VarB also.                                                                                           \n",
       "164   Variables VarA and VarB have a weak-to-moderate positive correlation. As VarA increases, VarB increases                                                                                                      \n",
       "167   There is a weak positive correlation between the variables.                                                                                                                                                  \n",
       "172   strong positive association with not many strong outliers                                                                                                                                                    \n",
       "173   likely independent, very slight positive correlation                                                                                                                                                         \n",
       "193   There is a moderate positive relationship between variables VarA and VarB. Higher values of VarA are associated with higher values of VarB, and a line of best fit can be matched with the data distribution.\n",
       "...                                                                                                                                                                                                             ...\n",
       "1177  Appears to be a very weak negative correlation between variables                                                                                                                                             \n",
       "1194  Weak relationship between them                                                                                                                                                                               \n",
       "1197  A moderate negative relationship between VarA and VarB. As VarA decreases, VarB also decreases.                                                                                                              \n",
       "1204  There is a moderately strong negative correlation.                                                                                                                                                           \n",
       "1215  There is a fairly strong relationship between VarA and VarB, as VarB decreases, VarA increases                                                                                                               \n",
       "1216  There is a lot of scatter but there seems to be a weak relation in that the bigger VarA is the smaller VarB will be                                                                                          \n",
       "1220  the graph shows a rough negative correlation with some anomaly's                                                                                                                                             \n",
       "1237  There is a slight negative correlation. As VarA increases, VarB decreases. The points are far apart and not showing a strong correlation.                                                                    \n",
       "1241  there is a slight negative correlation                                                                                                                                                                       \n",
       "1260  There appears to be a slight negative correlation between variables VarA and VarB in this chart.                                                                                                             \n",
       "1265  There's a moderate negative relationship - as VarA increases, VarB decreases by and large                                                                                                                    \n",
       "1283  There is a strong correlation, the higher the VarB variable the lower the VarA variable.                                                                                                                     \n",
       "1284  There is a moderate negative correlation between \"VarA\" and \"VarB\"; As VarB increases, VarA decreases                                                                                                        \n",
       "1287  They have a fairly strong negative correlation.                                                                                                                                                              \n",
       "1292  strong negative relationship                                                                                                                                                                                 \n",
       "1293  slight negative correlation, VarA is roughly (10-VarB)                                                                                                                                                       \n",
       "1302  There is a fairly strong negative correlation between variables. As VarA increases VarB decreases.                                                                                                           \n",
       "1337  Appears a weak negative correlation                                                                                                                                                                          \n",
       "1342  strong negative correlation                                                                                                                                                                                  \n",
       "1355  Strong correlation - an increase in VarA leads to a decrease in VarB                                                                                                                                         \n",
       "1357  A moderate negative relationship between VarA and VarB. As VarA decreases, VarB also decreases.                                                                                                              \n",
       "1359  Strong Negative correlation                                                                                                                                                                                  \n",
       "1364  There is a strong negative correlation between variables VarA and VarB.                                                                                                                                      \n",
       "1367  stronger relationship at central values                                                                                                                                                                      \n",
       "1389  strong negative correlation                                                                                                                                                                                  \n",
       "1390  strong negative correlation                                                                                                                                                                                  \n",
       "1393  There is a strong correlation between the decrease of VarB and the increase of VarA                                                                                                                          \n",
       "1394  Medium-strong Negative relationship.                                                                                                                                                                         \n",
       "1397  The is a slight negative correlation between VarA and VarB. As VarA increases, VarB decreases. Conversely, as b increases, a decreases                                                                       \n",
       "1425  There's a relatively strong negative relationship - as VarA increases, VarB decreases                                                                                                                        \n",
       "\n",
       "[185 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "display(filtered[['Answer']])\n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "magscale = {}\n",
    "with open('magscale.csv',encoding='utf-8-sig') as f:\n",
    "#     magscale = dict(filter(None, csv.reader(f)))\n",
    "    magscale = {k: int(v) for k,v in csv.reader(f)}\n",
    "#magscale = {\"strong\": 3, \"moderate\": 2, \"much\": 2, \"weak\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirscale = {}\n",
    "with open('dirscale.csv',encoding='utf-8-sig') as f:\n",
    "#     magscale = dict(filter(None, csv.reader(f)))\n",
    "    dirscale = {k: v for k,v in csv.reader(f)}\n",
    "#magscale = {\"strong\": 3, \"moderate\": 2, \"much\": 2, \"weak\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [],
   "source": [
    "regscale = {}\n",
    "with open('regscale.csv',encoding='utf-8-sig') as f:\n",
    "#     magscale = dict(filter(None, csv.reader(f)))\n",
    "    regscale = {k: v for k,v in csv.reader(f)}\n",
    "#magscale = {\"strong\": 3, \"moderate\": 2, \"much\": 2, \"weak\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [],
   "source": [
    "dscale = {}\n",
    "with open('dis_scale.csv',encoding='utf-8-sig') as f:\n",
    "#     magscale = dict(filter(None, csv.reader(f)))\n",
    "    dscale = {k: v for k,v in csv.reader(f)}\n",
    "#magscale = {\"strong\": 3, \"moderate\": 2, \"much\": 2, \"weak\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "pscale = {}\n",
    "with open('pscale.csv',encoding='utf-8-sig') as f:\n",
    "#     magscale = dict(filter(None, csv.reader(f)))\n",
    "    pscale = {k: v for k,v in csv.reader(f)}\n",
    "#magscale = {\"strong\": 3, \"moderate\": 2, \"much\": 2, \"weak\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second parameter for the assign_multi_value function should be replaced by whatever scale needs to be used from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_multi_value(sentence,scale):\n",
    "    svalues = {}\n",
    "    for word in sentence:\n",
    "        if word[0] in scale:\n",
    "            svalues[word[0]] = scale[word[0]]\n",
    "    return svalues\n",
    "filtered['multiscale'] = filtered['lemmatized'].apply(lambda x: assign_multi_value(x,magscale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'e1df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "ms = filtered['multiscale'].apply(pd.Series).reset_index().melt(id_vars='index').dropna()[['index', 'value']].set_index('index')\n",
    "e1df = pd.merge(filtered[['ResponseId','Question','lemma_cat_tagged']],ms,left_index=True,right_index=True)\n",
    "%store e1df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code above continues in wec-2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
